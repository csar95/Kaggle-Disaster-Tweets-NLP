{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "9649f1e3-1ba7-4163-b095-9015fd206f04",
      "metadata": {
        "id": "9649f1e3-1ba7-4163-b095-9015fd206f04"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "pd.set_option('display.max_rows', None)\n",
        "\n",
        "import numpy as np\n",
        "import re"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d03d1f90-0b1a-40c4-b20b-977978d7d2dc",
      "metadata": {
        "id": "d03d1f90-0b1a-40c4-b20b-977978d7d2dc"
      },
      "source": [
        "# Carga de datos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "2bcade7a-dcd3-4c30-b45c-48d1917834c5",
      "metadata": {
        "id": "2bcade7a-dcd3-4c30-b45c-48d1917834c5",
        "outputId": "33f77fbf-66bc-4795-a59f-08029e7f88ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7613, 5)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id           keyword  location  \\\n",
              "4112  5843         hailstorm  far away   \n",
              "6518  9321           survive     nj/ny   \n",
              "6400  9146  suicide%20bomber       NaN   \n",
              "\n",
              "                                                   text  target  \n",
              "4112  Calgary news weather and traffic for August 5 ...       0  \n",
              "6518  It's going on three years that we have been se...       0  \n",
              "6400  Suicide bomber kills 15 in Saudi security site...       1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9ca8162a-b3c4-4892-82b0-1b6a7f80e732\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>4112</th>\n",
              "      <td>5843</td>\n",
              "      <td>hailstorm</td>\n",
              "      <td>far away</td>\n",
              "      <td>Calgary news weather and traffic for August 5 ...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6518</th>\n",
              "      <td>9321</td>\n",
              "      <td>survive</td>\n",
              "      <td>nj/ny</td>\n",
              "      <td>It's going on three years that we have been se...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6400</th>\n",
              "      <td>9146</td>\n",
              "      <td>suicide%20bomber</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Suicide bomber kills 15 in Saudi security site...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9ca8162a-b3c4-4892-82b0-1b6a7f80e732')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9ca8162a-b3c4-4892-82b0-1b6a7f80e732 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9ca8162a-b3c4-4892-82b0-1b6a7f80e732');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "train_data = pd.read_csv(\"data/train.csv\")\n",
        "print(train_data.shape)\n",
        "train_data.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "45556839-00cd-4aab-917f-4132ad017a04",
      "metadata": {
        "id": "45556839-00cd-4aab-917f-4132ad017a04",
        "outputId": "f406d8de-a533-4ac2-a129-b5ad4f4e177a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(3263, 4)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id       keyword                   location  \\\n",
              "2900  9614  thunderstorm  Red Deer, Alberta, Canada   \n",
              "658   2151   catastrophe        Blackfield, England   \n",
              "1414  4653      engulfed                        NaN   \n",
              "\n",
              "                                                   text  \n",
              "2900  [HIGH PRIORITY] SEVERE THUNDERSTORM WATCH ENDE...  \n",
              "658   @robdelaney desperate to watch the last episod...  \n",
              "1414  He came to a land which was engulfed in tribal...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8c6f9e47-e594-4b7d-b49f-f3e6a4feeccb\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2900</th>\n",
              "      <td>9614</td>\n",
              "      <td>thunderstorm</td>\n",
              "      <td>Red Deer, Alberta, Canada</td>\n",
              "      <td>[HIGH PRIORITY] SEVERE THUNDERSTORM WATCH ENDE...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>658</th>\n",
              "      <td>2151</td>\n",
              "      <td>catastrophe</td>\n",
              "      <td>Blackfield, England</td>\n",
              "      <td>@robdelaney desperate to watch the last episod...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1414</th>\n",
              "      <td>4653</td>\n",
              "      <td>engulfed</td>\n",
              "      <td>NaN</td>\n",
              "      <td>He came to a land which was engulfed in tribal...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8c6f9e47-e594-4b7d-b49f-f3e6a4feeccb')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8c6f9e47-e594-4b7d-b49f-f3e6a4feeccb button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8c6f9e47-e594-4b7d-b49f-f3e6a4feeccb');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "test_data = pd.read_csv(\"data/test.csv\")\n",
        "print(test_data.shape)\n",
        "test_data.sample(3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "688e55e0-39a1-46a0-9a10-f9ec6b12917b",
      "metadata": {
        "id": "688e55e0-39a1-46a0-9a10-f9ec6b12917b",
        "outputId": "0d8e7411-0e8b-4dff-b94d-61f2f2c1c04c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10876, 6)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         id    keyword                        location  \\\n",
              "10119  8353       ruin  teen top ? jongsuk ? exo ? bts   \n",
              "8848   4059  displaced               San Francisco, CA   \n",
              "4500   6397  hurricane                        Vineyard   \n",
              "\n",
              "                                                    text  target   Dataset  \n",
              "10119  fUCK I CANT WAIT TO RUIN AUBREY'S WHOLE FIC AN...     NaN   Testing  \n",
              "8848   Next up: a charity program for disadvantaged p...     NaN   Testing  \n",
              "4500   @ChubbySquirrel_ @Hurricane_Surge this here is...     1.0  Training  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-21eaf4c7-9ef2-48f8-bae4-bbb334206178\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>Dataset</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>10119</th>\n",
              "      <td>8353</td>\n",
              "      <td>ruin</td>\n",
              "      <td>teen top ? jongsuk ? exo ? bts</td>\n",
              "      <td>fUCK I CANT WAIT TO RUIN AUBREY'S WHOLE FIC AN...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Testing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8848</th>\n",
              "      <td>4059</td>\n",
              "      <td>displaced</td>\n",
              "      <td>San Francisco, CA</td>\n",
              "      <td>Next up: a charity program for disadvantaged p...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Testing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4500</th>\n",
              "      <td>6397</td>\n",
              "      <td>hurricane</td>\n",
              "      <td>Vineyard</td>\n",
              "      <td>@ChubbySquirrel_ @Hurricane_Surge this here is...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Training</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-21eaf4c7-9ef2-48f8-bae4-bbb334206178')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-21eaf4c7-9ef2-48f8-bae4-bbb334206178 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-21eaf4c7-9ef2-48f8-bae4-bbb334206178');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "train_data['Dataset'] = 'Training'\n",
        "test_data['Dataset'] = 'Testing'\n",
        "data = pd.concat([train_data, test_data], ignore_index=True)\n",
        "print(data.shape)\n",
        "data.sample(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "96b2547e-ea47-4204-ac7d-b8c9ff2b47e5",
      "metadata": {
        "id": "96b2547e-ea47-4204-ac7d-b8c9ff2b47e5"
      },
      "source": [
        "# Preparación de los datos"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f058fb9e-1497-4974-b2ef-cb4e9bd1f482",
      "metadata": {
        "id": "f058fb9e-1497-4974-b2ef-cb4e9bd1f482"
      },
      "source": [
        "## Text Cleaning\n",
        "\n",
        "_(*) Taken from https://www.kaggle.com/code/gunesevitan/nlp-with-disaster-tweets-eda-cleaning-and-bert_\n",
        "\n",
        "Tweets require lots of cleaning but it is inefficient to clean every single tweet because that would consume too much time. A general approach must be implemented for cleaning.\n",
        "\n",
        "- The most common type of words that require cleaning in oov have punctuations at the start or end. Those words doesn't have embeddings because of the trailing punctuations. Punctuations #, @, !, ?, +, &, -, $, =, <, >, |, {, }, ^, ', (, ),[, ], *, %, ..., ', ., :, ; are separated from words\n",
        "- Special characters that are attached to words are removed completely\n",
        "- Contractions are expanded\n",
        "- Urls are removed\n",
        "- Character entity references are replaced with their actual symbols\n",
        "- Typos and slang are corrected, and informal abbreviations are written in their long forms\n",
        "- Some words are replaced with their acronyms and some words are grouped into one\n",
        "- Finally, hashtags and usernames contain lots of information about the context but they are written without spaces in between words so they don't have embeddings. Informational usernames and hashtags should be expanded but there are too many of them. I expanded as many as I could, but it takes too much time to run clean function after adding those replace calls."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "60d2d11d-c49c-45d3-9ef0-0ba175190c6e",
      "metadata": {
        "id": "60d2d11d-c49c-45d3-9ef0-0ba175190c6e",
        "outputId": "8a13ae62-20b0-476f-8a4f-11259b3f23a5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "CPU times: user 4min 26s, sys: 2.75 s, total: 4min 29s\n",
            "Wall time: 4min 46s\n"
          ]
        }
      ],
      "source": [
        "%%time\n",
        "\n",
        "def clean(tweet): \n",
        "            \n",
        "    # Special characters\n",
        "    tweet = re.sub(r\"\\x89Û_\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÒ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÓ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÏWhen\", \"When\", tweet)\n",
        "    tweet = re.sub(r\"\\x89ÛÏ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"China\\x89Ûªs\", \"China's\", tweet)\n",
        "    tweet = re.sub(r\"let\\x89Ûªs\", \"let's\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û÷\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Ûª\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û\\x9d\", \"\", tweet)\n",
        "    tweet = re.sub(r\"å_\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û¢\", \"\", tweet)\n",
        "    tweet = re.sub(r\"\\x89Û¢åÊ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"fromåÊwounds\", \"from wounds\", tweet)\n",
        "    tweet = re.sub(r\"åÊ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"åÈ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"JapÌ_n\", \"Japan\", tweet)    \n",
        "    tweet = re.sub(r\"Ì©\", \"e\", tweet)\n",
        "    tweet = re.sub(r\"å¨\", \"\", tweet)\n",
        "    tweet = re.sub(r\"SuruÌ¤\", \"Suruc\", tweet)\n",
        "    tweet = re.sub(r\"åÇ\", \"\", tweet)\n",
        "    tweet = re.sub(r\"å£3million\", \"3 million\", tweet)\n",
        "    tweet = re.sub(r\"åÀ\", \"\", tweet)\n",
        "    \n",
        "    # Contractions\n",
        "    tweet = re.sub(r\"he's\", \"he is\", tweet)\n",
        "    tweet = re.sub(r\"there's\", \"there is\", tweet)\n",
        "    tweet = re.sub(r\"We're\", \"We are\", tweet)\n",
        "    tweet = re.sub(r\"That's\", \"That is\", tweet)\n",
        "    tweet = re.sub(r\"won't\", \"will not\", tweet)\n",
        "    tweet = re.sub(r\"they're\", \"they are\", tweet)\n",
        "    tweet = re.sub(r\"Can't\", \"Cannot\", tweet)\n",
        "    tweet = re.sub(r\"wasn't\", \"was not\", tweet)\n",
        "    tweet = re.sub(r\"don\\x89Ûªt\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"aren't\", \"are not\", tweet)\n",
        "    tweet = re.sub(r\"isn't\", \"is not\", tweet)\n",
        "    tweet = re.sub(r\"What's\", \"What is\", tweet)\n",
        "    tweet = re.sub(r\"haven't\", \"have not\", tweet)\n",
        "    tweet = re.sub(r\"hasn't\", \"has not\", tweet)\n",
        "    tweet = re.sub(r\"There's\", \"There is\", tweet)\n",
        "    tweet = re.sub(r\"He's\", \"He is\", tweet)\n",
        "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"You're\", \"You are\", tweet)\n",
        "    tweet = re.sub(r\"I'M\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"shouldn't\", \"should not\", tweet)\n",
        "    tweet = re.sub(r\"wouldn't\", \"would not\", tweet)\n",
        "    tweet = re.sub(r\"i'm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ûªm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"I'm\", \"I am\", tweet)\n",
        "    tweet = re.sub(r\"Isn't\", \"is not\", tweet)\n",
        "    tweet = re.sub(r\"Here's\", \"Here is\", tweet)\n",
        "    tweet = re.sub(r\"you've\", \"you have\", tweet)\n",
        "    tweet = re.sub(r\"you\\x89Ûªve\", \"you have\", tweet)\n",
        "    tweet = re.sub(r\"we're\", \"we are\", tweet)\n",
        "    tweet = re.sub(r\"what's\", \"what is\", tweet)\n",
        "    tweet = re.sub(r\"couldn't\", \"could not\", tweet)\n",
        "    tweet = re.sub(r\"we've\", \"we have\", tweet)\n",
        "    tweet = re.sub(r\"it\\x89Ûªs\", \"it is\", tweet)\n",
        "    tweet = re.sub(r\"doesn\\x89Ûªt\", \"does not\", tweet)\n",
        "    tweet = re.sub(r\"It\\x89Ûªs\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"Here\\x89Ûªs\", \"Here is\", tweet)\n",
        "    tweet = re.sub(r\"who's\", \"who is\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ûªve\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"y'all\", \"you all\", tweet)\n",
        "    tweet = re.sub(r\"can\\x89Ûªt\", \"cannot\", tweet)\n",
        "    tweet = re.sub(r\"would've\", \"would have\", tweet)\n",
        "    tweet = re.sub(r\"it'll\", \"it will\", tweet)\n",
        "    tweet = re.sub(r\"we'll\", \"we will\", tweet)\n",
        "    tweet = re.sub(r\"wouldn\\x89Ûªt\", \"would not\", tweet)\n",
        "    tweet = re.sub(r\"We've\", \"We have\", tweet)\n",
        "    tweet = re.sub(r\"he'll\", \"he will\", tweet)\n",
        "    tweet = re.sub(r\"Y'all\", \"You all\", tweet)\n",
        "    tweet = re.sub(r\"Weren't\", \"Were not\", tweet)\n",
        "    tweet = re.sub(r\"Didn't\", \"Did not\", tweet)\n",
        "    tweet = re.sub(r\"they'll\", \"they will\", tweet)\n",
        "    tweet = re.sub(r\"they'd\", \"they would\", tweet)\n",
        "    tweet = re.sub(r\"DON'T\", \"DO NOT\", tweet)\n",
        "    tweet = re.sub(r\"That\\x89Ûªs\", \"That is\", tweet)\n",
        "    tweet = re.sub(r\"they've\", \"they have\", tweet)\n",
        "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"should've\", \"should have\", tweet)\n",
        "    tweet = re.sub(r\"You\\x89Ûªre\", \"You are\", tweet)\n",
        "    tweet = re.sub(r\"where's\", \"where is\", tweet)\n",
        "    tweet = re.sub(r\"Don\\x89Ûªt\", \"Do not\", tweet)\n",
        "    tweet = re.sub(r\"we'd\", \"we would\", tweet)\n",
        "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"weren't\", \"were not\", tweet)\n",
        "    tweet = re.sub(r\"They're\", \"They are\", tweet)\n",
        "    tweet = re.sub(r\"Can\\x89Ûªt\", \"Cannot\", tweet)\n",
        "    tweet = re.sub(r\"you\\x89Ûªll\", \"you will\", tweet)\n",
        "    tweet = re.sub(r\"I\\x89Ûªd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"let's\", \"let us\", tweet)\n",
        "    tweet = re.sub(r\"it's\", \"it is\", tweet)\n",
        "    tweet = re.sub(r\"can't\", \"cannot\", tweet)\n",
        "    tweet = re.sub(r\"don't\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"you're\", \"you are\", tweet)\n",
        "    tweet = re.sub(r\"i've\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"that's\", \"that is\", tweet)\n",
        "    tweet = re.sub(r\"i'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"doesn't\", \"does not\", tweet)\n",
        "    tweet = re.sub(r\"i'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"didn't\", \"did not\", tweet)\n",
        "    tweet = re.sub(r\"ain't\", \"am not\", tweet)\n",
        "    tweet = re.sub(r\"you'll\", \"you will\", tweet)\n",
        "    tweet = re.sub(r\"I've\", \"I have\", tweet)\n",
        "    tweet = re.sub(r\"Don't\", \"do not\", tweet)\n",
        "    tweet = re.sub(r\"I'll\", \"I will\", tweet)\n",
        "    tweet = re.sub(r\"I'd\", \"I would\", tweet)\n",
        "    tweet = re.sub(r\"Let's\", \"Let us\", tweet)\n",
        "    tweet = re.sub(r\"you'd\", \"You would\", tweet)\n",
        "    tweet = re.sub(r\"It's\", \"It is\", tweet)\n",
        "    tweet = re.sub(r\"Ain't\", \"am not\", tweet)\n",
        "    tweet = re.sub(r\"Haven't\", \"Have not\", tweet)\n",
        "    tweet = re.sub(r\"Could've\", \"Could have\", tweet)\n",
        "    tweet = re.sub(r\"youve\", \"you have\", tweet)  \n",
        "    tweet = re.sub(r\"donå«t\", \"do not\", tweet)   \n",
        "            \n",
        "    # Character entity references\n",
        "    tweet = re.sub(r\"&gt;\", \">\", tweet)\n",
        "    tweet = re.sub(r\"&lt;\", \"<\", tweet)\n",
        "    tweet = re.sub(r\"&amp;\", \"&\", tweet)\n",
        "    \n",
        "    # Typos, slang and informal abbreviations\n",
        "    tweet = re.sub(r\"w/e\", \"whatever\", tweet)\n",
        "    tweet = re.sub(r\"w/\", \"with\", tweet)\n",
        "    tweet = re.sub(r\"USAgov\", \"USA government\", tweet)\n",
        "    tweet = re.sub(r\"recentlu\", \"recently\", tweet)\n",
        "    tweet = re.sub(r\"Ph0tos\", \"Photos\", tweet)\n",
        "    tweet = re.sub(r\"amirite\", \"am I right\", tweet)\n",
        "    tweet = re.sub(r\"exp0sed\", \"exposed\", tweet)\n",
        "    tweet = re.sub(r\"<3\", \"love\", tweet)\n",
        "    tweet = re.sub(r\"amageddon\", \"armageddon\", tweet)\n",
        "    tweet = re.sub(r\"Trfc\", \"Traffic\", tweet)\n",
        "    tweet = re.sub(r\"8/5/2015\", \"2015-08-05\", tweet)\n",
        "    tweet = re.sub(r\"WindStorm\", \"Wind Storm\", tweet)\n",
        "    tweet = re.sub(r\"8/6/2015\", \"2015-08-06\", tweet)\n",
        "    tweet = re.sub(r\"10:38PM\", \"10:38 PM\", tweet)\n",
        "    tweet = re.sub(r\"10:30pm\", \"10:30 PM\", tweet)\n",
        "    tweet = re.sub(r\"16yr\", \"16 year\", tweet)\n",
        "    tweet = re.sub(r\"lmao\", \"laughing my ass off\", tweet)   \n",
        "    tweet = re.sub(r\"TRAUMATISED\", \"traumatized\", tweet)\n",
        "    \n",
        "    # Hashtags and usernames\n",
        "    tweet = re.sub(r\"IranDeal\", \"Iran Deal\", tweet)\n",
        "    tweet = re.sub(r\"ArianaGrande\", \"Ariana Grande\", tweet)\n",
        "    tweet = re.sub(r\"camilacabello97\", \"camila cabello\", tweet) \n",
        "    tweet = re.sub(r\"RondaRousey\", \"Ronda Rousey\", tweet)     \n",
        "    tweet = re.sub(r\"MTVHottest\", \"MTV Hottest\", tweet)\n",
        "    tweet = re.sub(r\"TrapMusic\", \"Trap Music\", tweet)\n",
        "    tweet = re.sub(r\"ProphetMuhammad\", \"Prophet Muhammad\", tweet)\n",
        "    tweet = re.sub(r\"PantherAttack\", \"Panther Attack\", tweet)\n",
        "    tweet = re.sub(r\"StrategicPatience\", \"Strategic Patience\", tweet)\n",
        "    tweet = re.sub(r\"socialnews\", \"social news\", tweet)\n",
        "    tweet = re.sub(r\"NASAHurricane\", \"NASA Hurricane\", tweet)\n",
        "    tweet = re.sub(r\"onlinecommunities\", \"online communities\", tweet)\n",
        "    tweet = re.sub(r\"humanconsumption\", \"human consumption\", tweet)\n",
        "    tweet = re.sub(r\"Typhoon-Devastated\", \"Typhoon Devastated\", tweet)\n",
        "    tweet = re.sub(r\"Meat-Loving\", \"Meat Loving\", tweet)\n",
        "    tweet = re.sub(r\"facialabuse\", \"facial abuse\", tweet)\n",
        "    tweet = re.sub(r\"LakeCounty\", \"Lake County\", tweet)\n",
        "    tweet = re.sub(r\"BeingAuthor\", \"Being Author\", tweet)\n",
        "    tweet = re.sub(r\"withheavenly\", \"with heavenly\", tweet)\n",
        "    tweet = re.sub(r\"thankU\", \"thank you\", tweet)\n",
        "    tweet = re.sub(r\"iTunesMusic\", \"iTunes Music\", tweet)\n",
        "    tweet = re.sub(r\"OffensiveContent\", \"Offensive Content\", tweet)\n",
        "    tweet = re.sub(r\"WorstSummerJob\", \"Worst Summer Job\", tweet)\n",
        "    tweet = re.sub(r\"HarryBeCareful\", \"Harry Be Careful\", tweet)\n",
        "    tweet = re.sub(r\"NASASolarSystem\", \"NASA Solar System\", tweet)\n",
        "    tweet = re.sub(r\"animalrescue\", \"animal rescue\", tweet)\n",
        "    tweet = re.sub(r\"KurtSchlichter\", \"Kurt Schlichter\", tweet)\n",
        "    tweet = re.sub(r\"aRmageddon\", \"armageddon\", tweet)\n",
        "    tweet = re.sub(r\"Throwingknifes\", \"Throwing knives\", tweet)\n",
        "    tweet = re.sub(r\"GodsLove\", \"God's Love\", tweet)\n",
        "    tweet = re.sub(r\"bookboost\", \"book boost\", tweet)\n",
        "    tweet = re.sub(r\"ibooklove\", \"I book love\", tweet)\n",
        "    tweet = re.sub(r\"NestleIndia\", \"Nestle India\", tweet)\n",
        "    tweet = re.sub(r\"realDonaldTrump\", \"Donald Trump\", tweet)\n",
        "    tweet = re.sub(r\"DavidVonderhaar\", \"David Vonderhaar\", tweet)\n",
        "    tweet = re.sub(r\"CecilTheLion\", \"Cecil The Lion\", tweet)\n",
        "    tweet = re.sub(r\"weathernetwork\", \"weather network\", tweet)\n",
        "    tweet = re.sub(r\"withBioterrorism&use\", \"with Bioterrorism & use\", tweet)\n",
        "    tweet = re.sub(r\"Hostage&2\", \"Hostage & 2\", tweet)\n",
        "    tweet = re.sub(r\"GOPDebate\", \"GOP Debate\", tweet)\n",
        "    tweet = re.sub(r\"RickPerry\", \"Rick Perry\", tweet)\n",
        "    tweet = re.sub(r\"frontpage\", \"front page\", tweet)\n",
        "    tweet = re.sub(r\"NewsInTweets\", \"News In Tweets\", tweet)\n",
        "    tweet = re.sub(r\"ViralSpell\", \"Viral Spell\", tweet)\n",
        "    tweet = re.sub(r\"til_now\", \"until now\", tweet)\n",
        "    tweet = re.sub(r\"volcanoinRussia\", \"volcano in Russia\", tweet)\n",
        "    tweet = re.sub(r\"ZippedNews\", \"Zipped News\", tweet)\n",
        "    tweet = re.sub(r\"MicheleBachman\", \"Michele Bachman\", tweet)\n",
        "    tweet = re.sub(r\"53inch\", \"53 inch\", tweet)\n",
        "    tweet = re.sub(r\"KerrickTrial\", \"Kerrick Trial\", tweet)\n",
        "    tweet = re.sub(r\"abstorm\", \"Alberta Storm\", tweet)\n",
        "    tweet = re.sub(r\"Beyhive\", \"Beyonce hive\", tweet)\n",
        "    tweet = re.sub(r\"IDFire\", \"Idaho Fire\", tweet)\n",
        "    tweet = re.sub(r\"DETECTADO\", \"Detected\", tweet)\n",
        "    tweet = re.sub(r\"RockyFire\", \"Rocky Fire\", tweet)\n",
        "    tweet = re.sub(r\"Listen/Buy\", \"Listen / Buy\", tweet)\n",
        "    tweet = re.sub(r\"NickCannon\", \"Nick Cannon\", tweet)\n",
        "    tweet = re.sub(r\"FaroeIslands\", \"Faroe Islands\", tweet)\n",
        "    tweet = re.sub(r\"yycstorm\", \"Calgary Storm\", tweet)\n",
        "    tweet = re.sub(r\"IDPs:\", \"Internally Displaced People :\", tweet)\n",
        "    tweet = re.sub(r\"ArtistsUnited\", \"Artists United\", tweet)\n",
        "    tweet = re.sub(r\"ClaytonBryant\", \"Clayton Bryant\", tweet)\n",
        "    tweet = re.sub(r\"jimmyfallon\", \"jimmy fallon\", tweet)\n",
        "    tweet = re.sub(r\"justinbieber\", \"justin bieber\", tweet)  \n",
        "    tweet = re.sub(r\"UTC2015\", \"UTC 2015\", tweet)\n",
        "    tweet = re.sub(r\"Time2015\", \"Time 2015\", tweet)\n",
        "    tweet = re.sub(r\"djicemoon\", \"dj icemoon\", tweet)\n",
        "    tweet = re.sub(r\"LivingSafely\", \"Living Safely\", tweet)\n",
        "    tweet = re.sub(r\"FIFA16\", \"Fifa 2016\", tweet)\n",
        "    tweet = re.sub(r\"thisiswhywecanthavenicethings\", \"this is why we cannot have nice things\", tweet)\n",
        "    tweet = re.sub(r\"bbcnews\", \"bbc news\", tweet)\n",
        "    tweet = re.sub(r\"UndergroundRailraod\", \"Underground Railraod\", tweet)\n",
        "    tweet = re.sub(r\"c4news\", \"c4 news\", tweet)\n",
        "    tweet = re.sub(r\"OBLITERATION\", \"obliteration\", tweet)\n",
        "    tweet = re.sub(r\"MUDSLIDE\", \"mudslide\", tweet)\n",
        "    tweet = re.sub(r\"NoSurrender\", \"No Surrender\", tweet)\n",
        "    tweet = re.sub(r\"NotExplained\", \"Not Explained\", tweet)\n",
        "    tweet = re.sub(r\"greatbritishbakeoff\", \"great british bake off\", tweet)\n",
        "    tweet = re.sub(r\"LondonFire\", \"London Fire\", tweet)\n",
        "    tweet = re.sub(r\"KOTAWeather\", \"KOTA Weather\", tweet)\n",
        "    tweet = re.sub(r\"LuchaUnderground\", \"Lucha Underground\", tweet)\n",
        "    tweet = re.sub(r\"KOIN6News\", \"KOIN 6 News\", tweet)\n",
        "    tweet = re.sub(r\"LiveOnK2\", \"Live On K2\", tweet)\n",
        "    tweet = re.sub(r\"9NewsGoldCoast\", \"9 News Gold Coast\", tweet)\n",
        "    tweet = re.sub(r\"nikeplus\", \"nike plus\", tweet)\n",
        "    tweet = re.sub(r\"david_cameron\", \"David Cameron\", tweet)\n",
        "    tweet = re.sub(r\"peterjukes\", \"Peter Jukes\", tweet)\n",
        "    tweet = re.sub(r\"JamesMelville\", \"James Melville\", tweet)\n",
        "    tweet = re.sub(r\"megynkelly\", \"Megyn Kelly\", tweet)\n",
        "    tweet = re.sub(r\"cnewslive\", \"C News Live\", tweet)\n",
        "    tweet = re.sub(r\"JamaicaObserver\", \"Jamaica Observer\", tweet)\n",
        "    tweet = re.sub(r\"TweetLikeItsSeptember11th2001\", \"Tweet like it is september 11th 2001\", tweet)\n",
        "    tweet = re.sub(r\"cbplawyers\", \"cbp lawyers\", tweet)\n",
        "    tweet = re.sub(r\"fewmoretweets\", \"few more tweets\", tweet)\n",
        "    tweet = re.sub(r\"BlackLivesMatter\", \"Black Lives Matter\", tweet)\n",
        "    tweet = re.sub(r\"cjoyner\", \"Chris Joyner\", tweet)\n",
        "    tweet = re.sub(r\"ENGvAUS\", \"England vs Australia\", tweet)\n",
        "    tweet = re.sub(r\"ScottWalker\", \"Scott Walker\", tweet)\n",
        "    tweet = re.sub(r\"MikeParrActor\", \"Michael Parr\", tweet)\n",
        "    tweet = re.sub(r\"4PlayThursdays\", \"Foreplay Thursdays\", tweet)\n",
        "    tweet = re.sub(r\"TGF2015\", \"Tontitown Grape Festival\", tweet)\n",
        "    tweet = re.sub(r\"realmandyrain\", \"Mandy Rain\", tweet)\n",
        "    tweet = re.sub(r\"GraysonDolan\", \"Grayson Dolan\", tweet)\n",
        "    tweet = re.sub(r\"ApolloBrown\", \"Apollo Brown\", tweet)\n",
        "    tweet = re.sub(r\"saddlebrooke\", \"Saddlebrooke\", tweet)\n",
        "    tweet = re.sub(r\"TontitownGrape\", \"Tontitown Grape\", tweet)\n",
        "    tweet = re.sub(r\"AbbsWinston\", \"Abbs Winston\", tweet)\n",
        "    tweet = re.sub(r\"ShaunKing\", \"Shaun King\", tweet)\n",
        "    tweet = re.sub(r\"MeekMill\", \"Meek Mill\", tweet)\n",
        "    tweet = re.sub(r\"TornadoGiveaway\", \"Tornado Giveaway\", tweet)\n",
        "    tweet = re.sub(r\"GRupdates\", \"GR updates\", tweet)\n",
        "    tweet = re.sub(r\"SouthDowns\", \"South Downs\", tweet)\n",
        "    tweet = re.sub(r\"braininjury\", \"brain injury\", tweet)\n",
        "    tweet = re.sub(r\"auspol\", \"Australian politics\", tweet)\n",
        "    tweet = re.sub(r\"PlannedParenthood\", \"Planned Parenthood\", tweet)\n",
        "    tweet = re.sub(r\"calgaryweather\", \"Calgary Weather\", tweet)\n",
        "    tweet = re.sub(r\"weallheartonedirection\", \"we all heart one direction\", tweet)\n",
        "    tweet = re.sub(r\"edsheeran\", \"Ed Sheeran\", tweet)\n",
        "    tweet = re.sub(r\"TrueHeroes\", \"True Heroes\", tweet)\n",
        "    tweet = re.sub(r\"S3XLEAK\", \"sex leak\", tweet)\n",
        "    tweet = re.sub(r\"ComplexMag\", \"Complex Magazine\", tweet)\n",
        "    tweet = re.sub(r\"TheAdvocateMag\", \"The Advocate Magazine\", tweet)\n",
        "    tweet = re.sub(r\"CityofCalgary\", \"City of Calgary\", tweet)\n",
        "    tweet = re.sub(r\"EbolaOutbreak\", \"Ebola Outbreak\", tweet)\n",
        "    tweet = re.sub(r\"SummerFate\", \"Summer Fate\", tweet)\n",
        "    tweet = re.sub(r\"RAmag\", \"Royal Academy Magazine\", tweet)\n",
        "    tweet = re.sub(r\"offers2go\", \"offers to go\", tweet)\n",
        "    tweet = re.sub(r\"foodscare\", \"food scare\", tweet)\n",
        "    tweet = re.sub(r\"MNPDNashville\", \"Metropolitan Nashville Police Department\", tweet)\n",
        "    tweet = re.sub(r\"TfLBusAlerts\", \"TfL Bus Alerts\", tweet)\n",
        "    tweet = re.sub(r\"GamerGate\", \"Gamer Gate\", tweet)\n",
        "    tweet = re.sub(r\"IHHen\", \"Humanitarian Relief\", tweet)\n",
        "    tweet = re.sub(r\"spinningbot\", \"spinning bot\", tweet)\n",
        "    tweet = re.sub(r\"ModiMinistry\", \"Modi Ministry\", tweet)\n",
        "    tweet = re.sub(r\"TAXIWAYS\", \"taxi ways\", tweet)\n",
        "    tweet = re.sub(r\"Calum5SOS\", \"Calum Hood\", tweet)\n",
        "    tweet = re.sub(r\"po_st\", \"po.st\", tweet)\n",
        "    tweet = re.sub(r\"scoopit\", \"scoop.it\", tweet)\n",
        "    tweet = re.sub(r\"UltimaLucha\", \"Ultima Lucha\", tweet)\n",
        "    tweet = re.sub(r\"JonathanFerrell\", \"Jonathan Ferrell\", tweet)\n",
        "    tweet = re.sub(r\"aria_ahrary\", \"Aria Ahrary\", tweet)\n",
        "    tweet = re.sub(r\"rapidcity\", \"Rapid City\", tweet)\n",
        "    tweet = re.sub(r\"OutBid\", \"outbid\", tweet)\n",
        "    tweet = re.sub(r\"lavenderpoetrycafe\", \"lavender poetry cafe\", tweet)\n",
        "    tweet = re.sub(r\"EudryLantiqua\", \"Eudry Lantiqua\", tweet)\n",
        "    tweet = re.sub(r\"15PM\", \"15 PM\", tweet)\n",
        "    tweet = re.sub(r\"OriginalFunko\", \"Funko\", tweet)\n",
        "    tweet = re.sub(r\"rightwaystan\", \"Richard Tan\", tweet)\n",
        "    tweet = re.sub(r\"CindyNoonan\", \"Cindy Noonan\", tweet)\n",
        "    tweet = re.sub(r\"RT_America\", \"RT America\", tweet)\n",
        "    tweet = re.sub(r\"narendramodi\", \"Narendra Modi\", tweet)\n",
        "    tweet = re.sub(r\"BakeOffFriends\", \"Bake Off Friends\", tweet)\n",
        "    tweet = re.sub(r\"TeamHendrick\", \"Hendrick Motorsports\", tweet)\n",
        "    tweet = re.sub(r\"alexbelloli\", \"Alex Belloli\", tweet)\n",
        "    tweet = re.sub(r\"itsjustinstuart\", \"Justin Stuart\", tweet)\n",
        "    tweet = re.sub(r\"gunsense\", \"gun sense\", tweet)\n",
        "    tweet = re.sub(r\"DebateQuestionsWeWantToHear\", \"debate questions we want to hear\", tweet)\n",
        "    tweet = re.sub(r\"RoyalCarribean\", \"Royal Carribean\", tweet)\n",
        "    tweet = re.sub(r\"samanthaturne19\", \"Samantha Turner\", tweet)\n",
        "    tweet = re.sub(r\"JonVoyage\", \"Jon Stewart\", tweet)\n",
        "    tweet = re.sub(r\"renew911health\", \"renew 911 health\", tweet)\n",
        "    tweet = re.sub(r\"SuryaRay\", \"Surya Ray\", tweet)\n",
        "    tweet = re.sub(r\"pattonoswalt\", \"Patton Oswalt\", tweet)\n",
        "    tweet = re.sub(r\"minhazmerchant\", \"Minhaz Merchant\", tweet)\n",
        "    tweet = re.sub(r\"TLVFaces\", \"Israel Diaspora Coalition\", tweet)\n",
        "    tweet = re.sub(r\"pmarca\", \"Marc Andreessen\", tweet)\n",
        "    tweet = re.sub(r\"pdx911\", \"Portland Police\", tweet)\n",
        "    tweet = re.sub(r\"jamaicaplain\", \"Jamaica Plain\", tweet)\n",
        "    tweet = re.sub(r\"Japton\", \"Arkansas\", tweet)\n",
        "    tweet = re.sub(r\"RouteComplex\", \"Route Complex\", tweet)\n",
        "    tweet = re.sub(r\"INSubcontinent\", \"Indian Subcontinent\", tweet)\n",
        "    tweet = re.sub(r\"NJTurnpike\", \"New Jersey Turnpike\", tweet)\n",
        "    tweet = re.sub(r\"Politifiact\", \"PolitiFact\", tweet)\n",
        "    tweet = re.sub(r\"Hiroshima70\", \"Hiroshima\", tweet)\n",
        "    tweet = re.sub(r\"GMMBC\", \"Greater Mt Moriah Baptist Church\", tweet)\n",
        "    tweet = re.sub(r\"versethe\", \"verse the\", tweet)\n",
        "    tweet = re.sub(r\"TubeStrike\", \"Tube Strike\", tweet)\n",
        "    tweet = re.sub(r\"MissionHills\", \"Mission Hills\", tweet)\n",
        "    tweet = re.sub(r\"ProtectDenaliWolves\", \"Protect Denali Wolves\", tweet)\n",
        "    tweet = re.sub(r\"NANKANA\", \"Nankana\", tweet)\n",
        "    tweet = re.sub(r\"SAHIB\", \"Sahib\", tweet)\n",
        "    tweet = re.sub(r\"PAKPATTAN\", \"Pakpattan\", tweet)\n",
        "    tweet = re.sub(r\"Newz_Sacramento\", \"News Sacramento\", tweet)\n",
        "    tweet = re.sub(r\"gofundme\", \"go fund me\", tweet)\n",
        "    tweet = re.sub(r\"pmharper\", \"Stephen Harper\", tweet)\n",
        "    tweet = re.sub(r\"IvanBerroa\", \"Ivan Berroa\", tweet)\n",
        "    tweet = re.sub(r\"LosDelSonido\", \"Los Del Sonido\", tweet)\n",
        "    tweet = re.sub(r\"bancodeseries\", \"banco de series\", tweet)\n",
        "    tweet = re.sub(r\"timkaine\", \"Tim Kaine\", tweet)\n",
        "    tweet = re.sub(r\"IdentityTheft\", \"Identity Theft\", tweet)\n",
        "    tweet = re.sub(r\"AllLivesMatter\", \"All Lives Matter\", tweet)\n",
        "    tweet = re.sub(r\"mishacollins\", \"Misha Collins\", tweet)\n",
        "    tweet = re.sub(r\"BillNeelyNBC\", \"Bill Neely\", tweet)\n",
        "    tweet = re.sub(r\"BeClearOnCancer\", \"be clear on cancer\", tweet)\n",
        "    tweet = re.sub(r\"Kowing\", \"Knowing\", tweet)\n",
        "    tweet = re.sub(r\"ScreamQueens\", \"Scream Queens\", tweet)\n",
        "    tweet = re.sub(r\"AskCharley\", \"Ask Charley\", tweet)\n",
        "    tweet = re.sub(r\"BlizzHeroes\", \"Heroes of the Storm\", tweet)\n",
        "    tweet = re.sub(r\"BradleyBrad47\", \"Bradley Brad\", tweet)\n",
        "    tweet = re.sub(r\"HannaPH\", \"Typhoon Hanna\", tweet)\n",
        "    tweet = re.sub(r\"meinlcymbals\", \"MEINL Cymbals\", tweet)\n",
        "    tweet = re.sub(r\"Ptbo\", \"Peterborough\", tweet)\n",
        "    tweet = re.sub(r\"cnnbrk\", \"CNN Breaking News\", tweet)\n",
        "    tweet = re.sub(r\"IndianNews\", \"Indian News\", tweet)\n",
        "    tweet = re.sub(r\"savebees\", \"save bees\", tweet)\n",
        "    tweet = re.sub(r\"GreenHarvard\", \"Green Harvard\", tweet)\n",
        "    tweet = re.sub(r\"StandwithPP\", \"Stand with planned parenthood\", tweet)\n",
        "    tweet = re.sub(r\"hermancranston\", \"Herman Cranston\", tweet)\n",
        "    tweet = re.sub(r\"WMUR9\", \"WMUR-TV\", tweet)\n",
        "    tweet = re.sub(r\"RockBottomRadFM\", \"Rock Bottom Radio\", tweet)\n",
        "    tweet = re.sub(r\"ameenshaikh3\", \"Ameen Shaikh\", tweet)\n",
        "    tweet = re.sub(r\"ProSyn\", \"Project Syndicate\", tweet)\n",
        "    tweet = re.sub(r\"Daesh\", \"ISIS\", tweet)\n",
        "    tweet = re.sub(r\"s2g\", \"swear to god\", tweet)\n",
        "    tweet = re.sub(r\"listenlive\", \"listen live\", tweet)\n",
        "    tweet = re.sub(r\"CDCgov\", \"Centers for Disease Control and Prevention\", tweet)\n",
        "    tweet = re.sub(r\"FoxNew\", \"Fox News\", tweet)\n",
        "    tweet = re.sub(r\"CBSBigBrother\", \"Big Brother\", tweet)\n",
        "    tweet = re.sub(r\"JulieDiCaro\", \"Julie DiCaro\", tweet)\n",
        "    tweet = re.sub(r\"theadvocatemag\", \"The Advocate Magazine\", tweet)\n",
        "    tweet = re.sub(r\"RohnertParkDPS\", \"Rohnert Park Police Department\", tweet)\n",
        "    tweet = re.sub(r\"THISIZBWRIGHT\", \"Bonnie Wright\", tweet)\n",
        "    tweet = re.sub(r\"Popularmmos\", \"Popular MMOs\", tweet)\n",
        "    tweet = re.sub(r\"WildHorses\", \"Wild Horses\", tweet)\n",
        "    tweet = re.sub(r\"FantasticFour\", \"Fantastic Four\", tweet)\n",
        "    tweet = re.sub(r\"HORNDALE\", \"Horndale\", tweet)\n",
        "    tweet = re.sub(r\"PINER\", \"Piner\", tweet)\n",
        "    tweet = re.sub(r\"BathAndNorthEastSomerset\", \"Bath and North East Somerset\", tweet)\n",
        "    tweet = re.sub(r\"thatswhatfriendsarefor\", \"that is what friends are for\", tweet)\n",
        "    tweet = re.sub(r\"residualincome\", \"residual income\", tweet)\n",
        "    tweet = re.sub(r\"YahooNewsDigest\", \"Yahoo News Digest\", tweet)\n",
        "    tweet = re.sub(r\"MalaysiaAirlines\", \"Malaysia Airlines\", tweet)\n",
        "    tweet = re.sub(r\"AmazonDeals\", \"Amazon Deals\", tweet)\n",
        "    tweet = re.sub(r\"MissCharleyWebb\", \"Charley Webb\", tweet)\n",
        "    tweet = re.sub(r\"shoalstraffic\", \"shoals traffic\", tweet)\n",
        "    tweet = re.sub(r\"GeorgeFoster72\", \"George Foster\", tweet)\n",
        "    tweet = re.sub(r\"pop2015\", \"pop 2015\", tweet)\n",
        "    tweet = re.sub(r\"_PokemonCards_\", \"Pokemon Cards\", tweet)\n",
        "    tweet = re.sub(r\"DianneG\", \"Dianne Gallagher\", tweet)\n",
        "    tweet = re.sub(r\"KashmirConflict\", \"Kashmir Conflict\", tweet)\n",
        "    tweet = re.sub(r\"BritishBakeOff\", \"British Bake Off\", tweet)\n",
        "    tweet = re.sub(r\"FreeKashmir\", \"Free Kashmir\", tweet)\n",
        "    tweet = re.sub(r\"mattmosley\", \"Matt Mosley\", tweet)\n",
        "    tweet = re.sub(r\"BishopFred\", \"Bishop Fred\", tweet)\n",
        "    tweet = re.sub(r\"EndConflict\", \"End Conflict\", tweet)\n",
        "    tweet = re.sub(r\"EndOccupation\", \"End Occupation\", tweet)\n",
        "    tweet = re.sub(r\"UNHEALED\", \"unhealed\", tweet)\n",
        "    tweet = re.sub(r\"CharlesDagnall\", \"Charles Dagnall\", tweet)\n",
        "    tweet = re.sub(r\"Latestnews\", \"Latest news\", tweet)\n",
        "    tweet = re.sub(r\"KindleCountdown\", \"Kindle Countdown\", tweet)\n",
        "    tweet = re.sub(r\"NoMoreHandouts\", \"No More Handouts\", tweet)\n",
        "    tweet = re.sub(r\"datingtips\", \"dating tips\", tweet)\n",
        "    tweet = re.sub(r\"charlesadler\", \"Charles Adler\", tweet)\n",
        "    tweet = re.sub(r\"twia\", \"Texas Windstorm Insurance Association\", tweet)\n",
        "    tweet = re.sub(r\"txlege\", \"Texas Legislature\", tweet)\n",
        "    tweet = re.sub(r\"WindstormInsurer\", \"Windstorm Insurer\", tweet)\n",
        "    tweet = re.sub(r\"Newss\", \"News\", tweet)\n",
        "    tweet = re.sub(r\"hempoil\", \"hemp oil\", tweet)\n",
        "    tweet = re.sub(r\"CommoditiesAre\", \"Commodities are\", tweet)\n",
        "    tweet = re.sub(r\"tubestrike\", \"tube strike\", tweet)\n",
        "    tweet = re.sub(r\"JoeNBC\", \"Joe Scarborough\", tweet)\n",
        "    tweet = re.sub(r\"LiteraryCakes\", \"Literary Cakes\", tweet)\n",
        "    tweet = re.sub(r\"TI5\", \"The International 5\", tweet)\n",
        "    tweet = re.sub(r\"thehill\", \"the hill\", tweet)\n",
        "    tweet = re.sub(r\"3others\", \"3 others\", tweet)\n",
        "    tweet = re.sub(r\"stighefootball\", \"Sam Tighe\", tweet)\n",
        "    tweet = re.sub(r\"whatstheimportantvideo\", \"what is the important video\", tweet)\n",
        "    tweet = re.sub(r\"ClaudioMeloni\", \"Claudio Meloni\", tweet)\n",
        "    tweet = re.sub(r\"DukeSkywalker\", \"Duke Skywalker\", tweet)\n",
        "    tweet = re.sub(r\"carsonmwr\", \"Fort Carson\", tweet)\n",
        "    tweet = re.sub(r\"offdishduty\", \"off dish duty\", tweet)\n",
        "    tweet = re.sub(r\"andword\", \"and word\", tweet)\n",
        "    tweet = re.sub(r\"rhodeisland\", \"Rhode Island\", tweet)\n",
        "    tweet = re.sub(r\"easternoregon\", \"Eastern Oregon\", tweet)\n",
        "    tweet = re.sub(r\"WAwildfire\", \"Washington Wildfire\", tweet)\n",
        "    tweet = re.sub(r\"fingerrockfire\", \"Finger Rock Fire\", tweet)\n",
        "    tweet = re.sub(r\"57am\", \"57 am\", tweet)\n",
        "    tweet = re.sub(r\"fingerrockfire\", \"Finger Rock Fire\", tweet)\n",
        "    tweet = re.sub(r\"JacobHoggard\", \"Jacob Hoggard\", tweet)\n",
        "    tweet = re.sub(r\"newnewnew\", \"new new new\", tweet)\n",
        "    tweet = re.sub(r\"under50\", \"under 50\", tweet)\n",
        "    tweet = re.sub(r\"getitbeforeitsgone\", \"get it before it is gone\", tweet)\n",
        "    tweet = re.sub(r\"freshoutofthebox\", \"fresh out of the box\", tweet)\n",
        "    tweet = re.sub(r\"amwriting\", \"am writing\", tweet)\n",
        "    tweet = re.sub(r\"Bokoharm\", \"Boko Haram\", tweet)\n",
        "    tweet = re.sub(r\"Nowlike\", \"Now like\", tweet)\n",
        "    tweet = re.sub(r\"seasonfrom\", \"season from\", tweet)\n",
        "    tweet = re.sub(r\"epicente\", \"epicenter\", tweet)\n",
        "    tweet = re.sub(r\"epicenterr\", \"epicenter\", tweet)\n",
        "    tweet = re.sub(r\"sicklife\", \"sick life\", tweet)\n",
        "    tweet = re.sub(r\"yycweather\", \"Calgary Weather\", tweet)\n",
        "    tweet = re.sub(r\"calgarysun\", \"Calgary Sun\", tweet)\n",
        "    tweet = re.sub(r\"approachng\", \"approaching\", tweet)\n",
        "    tweet = re.sub(r\"evng\", \"evening\", tweet)\n",
        "    tweet = re.sub(r\"Sumthng\", \"something\", tweet)\n",
        "    tweet = re.sub(r\"EllenPompeo\", \"Ellen Pompeo\", tweet)\n",
        "    tweet = re.sub(r\"shondarhimes\", \"Shonda Rhimes\", tweet)\n",
        "    tweet = re.sub(r\"ABCNetwork\", \"ABC Network\", tweet)\n",
        "    tweet = re.sub(r\"SushmaSwaraj\", \"Sushma Swaraj\", tweet)\n",
        "    tweet = re.sub(r\"pray4japan\", \"Pray for Japan\", tweet)\n",
        "    tweet = re.sub(r\"hope4japan\", \"Hope for Japan\", tweet)\n",
        "    tweet = re.sub(r\"Illusionimagess\", \"Illusion images\", tweet)\n",
        "    tweet = re.sub(r\"SummerUnderTheStars\", \"Summer Under The Stars\", tweet)\n",
        "    tweet = re.sub(r\"ShallWeDance\", \"Shall We Dance\", tweet)\n",
        "    tweet = re.sub(r\"TCMParty\", \"TCM Party\", tweet)\n",
        "    tweet = re.sub(r\"marijuananews\", \"marijuana news\", tweet)\n",
        "    tweet = re.sub(r\"onbeingwithKristaTippett\", \"on being with Krista Tippett\", tweet)\n",
        "    tweet = re.sub(r\"Beingtweets\", \"Being tweets\", tweet)\n",
        "    tweet = re.sub(r\"newauthors\", \"new authors\", tweet)\n",
        "    tweet = re.sub(r\"remedyyyy\", \"remedy\", tweet)\n",
        "    tweet = re.sub(r\"44PM\", \"44 PM\", tweet)\n",
        "    tweet = re.sub(r\"HeadlinesApp\", \"Headlines App\", tweet)\n",
        "    tweet = re.sub(r\"40PM\", \"40 PM\", tweet)\n",
        "    tweet = re.sub(r\"myswc\", \"Severe Weather Center\", tweet)\n",
        "    tweet = re.sub(r\"ithats\", \"that is\", tweet)\n",
        "    tweet = re.sub(r\"icouldsitinthismomentforever\", \"I could sit in this moment forever\", tweet)\n",
        "    tweet = re.sub(r\"FatLoss\", \"Fat Loss\", tweet)\n",
        "    tweet = re.sub(r\"02PM\", \"02 PM\", tweet)\n",
        "    tweet = re.sub(r\"MetroFmTalk\", \"Metro Fm Talk\", tweet)\n",
        "    tweet = re.sub(r\"Bstrd\", \"bastard\", tweet)\n",
        "    tweet = re.sub(r\"bldy\", \"bloody\", tweet)\n",
        "    tweet = re.sub(r\"MetrofmTalk\", \"Metro Fm Talk\", tweet)\n",
        "    tweet = re.sub(r\"terrorismturn\", \"terrorism turn\", tweet)\n",
        "    tweet = re.sub(r\"BBCNewsAsia\", \"BBC News Asia\", tweet)\n",
        "    tweet = re.sub(r\"BehindTheScenes\", \"Behind The Scenes\", tweet)\n",
        "    tweet = re.sub(r\"GeorgeTakei\", \"George Takei\", tweet)\n",
        "    tweet = re.sub(r\"WomensWeeklyMag\", \"Womens Weekly Magazine\", tweet)\n",
        "    tweet = re.sub(r\"SurvivorsGuidetoEarth\", \"Survivors Guide to Earth\", tweet)\n",
        "    tweet = re.sub(r\"incubusband\", \"incubus band\", tweet)\n",
        "    tweet = re.sub(r\"Babypicturethis\", \"Baby picture this\", tweet)\n",
        "    tweet = re.sub(r\"BombEffects\", \"Bomb Effects\", tweet)\n",
        "    tweet = re.sub(r\"win10\", \"Windows 10\", tweet)\n",
        "    tweet = re.sub(r\"idkidk\", \"I do not know I do not know\", tweet)\n",
        "    tweet = re.sub(r\"TheWalkingDead\", \"The Walking Dead\", tweet)\n",
        "    tweet = re.sub(r\"amyschumer\", \"Amy Schumer\", tweet)\n",
        "    tweet = re.sub(r\"crewlist\", \"crew list\", tweet)\n",
        "    tweet = re.sub(r\"Erdogans\", \"Erdogan\", tweet)\n",
        "    tweet = re.sub(r\"BBCLive\", \"BBC Live\", tweet)\n",
        "    tweet = re.sub(r\"TonyAbbottMHR\", \"Tony Abbott\", tweet)\n",
        "    tweet = re.sub(r\"paulmyerscough\", \"Paul Myerscough\", tweet)\n",
        "    tweet = re.sub(r\"georgegallagher\", \"George Gallagher\", tweet)\n",
        "    tweet = re.sub(r\"JimmieJohnson\", \"Jimmie Johnson\", tweet)\n",
        "    tweet = re.sub(r\"pctool\", \"pc tool\", tweet)\n",
        "    tweet = re.sub(r\"DoingHashtagsRight\", \"Doing Hashtags Right\", tweet)\n",
        "    tweet = re.sub(r\"ThrowbackThursday\", \"Throwback Thursday\", tweet)\n",
        "    tweet = re.sub(r\"SnowBackSunday\", \"Snowback Sunday\", tweet)\n",
        "    tweet = re.sub(r\"LakeEffect\", \"Lake Effect\", tweet)\n",
        "    tweet = re.sub(r\"RTphotographyUK\", \"Richard Thomas Photography UK\", tweet)\n",
        "    tweet = re.sub(r\"BigBang_CBS\", \"Big Bang CBS\", tweet)\n",
        "    tweet = re.sub(r\"writerslife\", \"writers life\", tweet)\n",
        "    tweet = re.sub(r\"NaturalBirth\", \"Natural Birth\", tweet)\n",
        "    tweet = re.sub(r\"UnusualWords\", \"Unusual Words\", tweet)\n",
        "    tweet = re.sub(r\"wizkhalifa\", \"Wiz Khalifa\", tweet)\n",
        "    tweet = re.sub(r\"acreativedc\", \"a creative DC\", tweet)\n",
        "    tweet = re.sub(r\"vscodc\", \"vsco DC\", tweet)\n",
        "    tweet = re.sub(r\"VSCOcam\", \"vsco camera\", tweet)\n",
        "    tweet = re.sub(r\"TheBEACHDC\", \"The beach DC\", tweet)\n",
        "    tweet = re.sub(r\"buildingmuseum\", \"building museum\", tweet)\n",
        "    tweet = re.sub(r\"WorldOil\", \"World Oil\", tweet)\n",
        "    tweet = re.sub(r\"redwedding\", \"red wedding\", tweet)\n",
        "    tweet = re.sub(r\"AmazingRaceCanada\", \"Amazing Race Canada\", tweet)\n",
        "    tweet = re.sub(r\"WakeUpAmerica\", \"Wake Up America\", tweet)\n",
        "    tweet = re.sub(r\"\\\\Allahuakbar\\\\\", \"Allahu Akbar\", tweet)\n",
        "    tweet = re.sub(r\"bleased\", \"blessed\", tweet)\n",
        "    tweet = re.sub(r\"nigeriantribune\", \"Nigerian Tribune\", tweet)\n",
        "    tweet = re.sub(r\"HIDEO_KOJIMA_EN\", \"Hideo Kojima\", tweet)\n",
        "    tweet = re.sub(r\"FusionFestival\", \"Fusion Festival\", tweet)\n",
        "    tweet = re.sub(r\"50Mixed\", \"50 Mixed\", tweet)\n",
        "    tweet = re.sub(r\"NoAgenda\", \"No Agenda\", tweet)\n",
        "    tweet = re.sub(r\"WhiteGenocide\", \"White Genocide\", tweet)\n",
        "    tweet = re.sub(r\"dirtylying\", \"dirty lying\", tweet)\n",
        "    tweet = re.sub(r\"SyrianRefugees\", \"Syrian Refugees\", tweet)\n",
        "    tweet = re.sub(r\"changetheworld\", \"change the world\", tweet)\n",
        "    tweet = re.sub(r\"Ebolacase\", \"Ebola case\", tweet)\n",
        "    tweet = re.sub(r\"mcgtech\", \"mcg technologies\", tweet)\n",
        "    tweet = re.sub(r\"withweapons\", \"with weapons\", tweet)\n",
        "    tweet = re.sub(r\"advancedwarfare\", \"advanced warfare\", tweet)\n",
        "    tweet = re.sub(r\"letsFootball\", \"let us Football\", tweet)\n",
        "    tweet = re.sub(r\"LateNiteMix\", \"late night mix\", tweet)\n",
        "    tweet = re.sub(r\"PhilCollinsFeed\", \"Phil Collins\", tweet)\n",
        "    tweet = re.sub(r\"RudyHavenstein\", \"Rudy Havenstein\", tweet)\n",
        "    tweet = re.sub(r\"22PM\", \"22 PM\", tweet)\n",
        "    tweet = re.sub(r\"54am\", \"54 AM\", tweet)\n",
        "    tweet = re.sub(r\"38am\", \"38 AM\", tweet)\n",
        "    tweet = re.sub(r\"OldFolkExplainStuff\", \"Old Folk Explain Stuff\", tweet)\n",
        "    tweet = re.sub(r\"BlacklivesMatter\", \"Black Lives Matter\", tweet)\n",
        "    tweet = re.sub(r\"InsaneLimits\", \"Insane Limits\", tweet)\n",
        "    tweet = re.sub(r\"youcantsitwithus\", \"you cannot sit with us\", tweet)\n",
        "    tweet = re.sub(r\"2k15\", \"2015\", tweet)\n",
        "    tweet = re.sub(r\"TheIran\", \"Iran\", tweet)\n",
        "    tweet = re.sub(r\"JimmyFallon\", \"Jimmy Fallon\", tweet)\n",
        "    tweet = re.sub(r\"AlbertBrooks\", \"Albert Brooks\", tweet)\n",
        "    tweet = re.sub(r\"defense_news\", \"defense news\", tweet)\n",
        "    tweet = re.sub(r\"nuclearrcSA\", \"Nuclear Risk Control Self Assessment\", tweet)\n",
        "    tweet = re.sub(r\"Auspol\", \"Australia Politics\", tweet)\n",
        "    tweet = re.sub(r\"NuclearPower\", \"Nuclear Power\", tweet)\n",
        "    tweet = re.sub(r\"WhiteTerrorism\", \"White Terrorism\", tweet)\n",
        "    tweet = re.sub(r\"truthfrequencyradio\", \"Truth Frequency Radio\", tweet)\n",
        "    tweet = re.sub(r\"ErasureIsNotEquality\", \"Erasure is not equality\", tweet)\n",
        "    tweet = re.sub(r\"ProBonoNews\", \"Pro Bono News\", tweet)\n",
        "    tweet = re.sub(r\"JakartaPost\", \"Jakarta Post\", tweet)\n",
        "    tweet = re.sub(r\"toopainful\", \"too painful\", tweet)\n",
        "    tweet = re.sub(r\"melindahaunton\", \"Melinda Haunton\", tweet)\n",
        "    tweet = re.sub(r\"NoNukes\", \"No Nukes\", tweet)\n",
        "    tweet = re.sub(r\"curryspcworld\", \"Currys PC World\", tweet)\n",
        "    tweet = re.sub(r\"ineedcake\", \"I need cake\", tweet)\n",
        "    tweet = re.sub(r\"blackforestgateau\", \"black forest gateau\", tweet)\n",
        "    tweet = re.sub(r\"BBCOne\", \"BBC One\", tweet)\n",
        "    tweet = re.sub(r\"AlexxPage\", \"Alex Page\", tweet)\n",
        "    tweet = re.sub(r\"jonathanserrie\", \"Jonathan Serrie\", tweet)\n",
        "    tweet = re.sub(r\"SocialJerkBlog\", \"Social Jerk Blog\", tweet)\n",
        "    tweet = re.sub(r\"ChelseaVPeretti\", \"Chelsea Peretti\", tweet)\n",
        "    tweet = re.sub(r\"irongiant\", \"iron giant\", tweet)\n",
        "    tweet = re.sub(r\"RonFunches\", \"Ron Funches\", tweet)\n",
        "    tweet = re.sub(r\"TimCook\", \"Tim Cook\", tweet)\n",
        "    tweet = re.sub(r\"sebastianstanisaliveandwell\", \"Sebastian Stan is alive and well\", tweet)\n",
        "    tweet = re.sub(r\"Madsummer\", \"Mad summer\", tweet)\n",
        "    tweet = re.sub(r\"NowYouKnow\", \"Now you know\", tweet)\n",
        "    tweet = re.sub(r\"concertphotography\", \"concert photography\", tweet)\n",
        "    tweet = re.sub(r\"TomLandry\", \"Tom Landry\", tweet)\n",
        "    tweet = re.sub(r\"showgirldayoff\", \"show girl day off\", tweet)\n",
        "    tweet = re.sub(r\"Yougslavia\", \"Yugoslavia\", tweet)\n",
        "    tweet = re.sub(r\"QuantumDataInformatics\", \"Quantum Data Informatics\", tweet)\n",
        "    tweet = re.sub(r\"FromTheDesk\", \"From The Desk\", tweet)\n",
        "    tweet = re.sub(r\"TheaterTrial\", \"Theater Trial\", tweet)\n",
        "    tweet = re.sub(r\"CatoInstitute\", \"Cato Institute\", tweet)\n",
        "    tweet = re.sub(r\"EmekaGift\", \"Emeka Gift\", tweet)\n",
        "    tweet = re.sub(r\"LetsBe_Rational\", \"Let us be rational\", tweet)\n",
        "    tweet = re.sub(r\"Cynicalreality\", \"Cynical reality\", tweet)\n",
        "    tweet = re.sub(r\"FredOlsenCruise\", \"Fred Olsen Cruise\", tweet)\n",
        "    tweet = re.sub(r\"NotSorry\", \"not sorry\", tweet)\n",
        "    tweet = re.sub(r\"UseYourWords\", \"use your words\", tweet)\n",
        "    tweet = re.sub(r\"WordoftheDay\", \"word of the day\", tweet)\n",
        "    tweet = re.sub(r\"Dictionarycom\", \"Dictionary.com\", tweet)\n",
        "    tweet = re.sub(r\"TheBrooklynLife\", \"The Brooklyn Life\", tweet)\n",
        "    tweet = re.sub(r\"jokethey\", \"joke they\", tweet)\n",
        "    tweet = re.sub(r\"nflweek1picks\", \"NFL week 1 picks\", tweet)\n",
        "    tweet = re.sub(r\"uiseful\", \"useful\", tweet)\n",
        "    tweet = re.sub(r\"JusticeDotOrg\", \"The American Association for Justice\", tweet)\n",
        "    tweet = re.sub(r\"autoaccidents\", \"auto accidents\", tweet)\n",
        "    tweet = re.sub(r\"SteveGursten\", \"Steve Gursten\", tweet)\n",
        "    tweet = re.sub(r\"MichiganAutoLaw\", \"Michigan Auto Law\", tweet)\n",
        "    tweet = re.sub(r\"birdgang\", \"bird gang\", tweet)\n",
        "    tweet = re.sub(r\"nflnetwork\", \"NFL Network\", tweet)\n",
        "    tweet = re.sub(r\"NYDNSports\", \"NY Daily News Sports\", tweet)\n",
        "    tweet = re.sub(r\"RVacchianoNYDN\", \"Ralph Vacchiano NY Daily News\", tweet)\n",
        "    tweet = re.sub(r\"EdmontonEsks\", \"Edmonton Eskimos\", tweet)\n",
        "    tweet = re.sub(r\"david_brelsford\", \"David Brelsford\", tweet)\n",
        "    tweet = re.sub(r\"TOI_India\", \"The Times of India\", tweet)\n",
        "    tweet = re.sub(r\"hegot\", \"he got\", tweet)\n",
        "    tweet = re.sub(r\"SkinsOn9\", \"Skins on 9\", tweet)\n",
        "    tweet = re.sub(r\"sothathappened\", \"so that happened\", tweet)\n",
        "    tweet = re.sub(r\"LCOutOfDoors\", \"LC Out Of Doors\", tweet)\n",
        "    tweet = re.sub(r\"NationFirst\", \"Nation First\", tweet)\n",
        "    tweet = re.sub(r\"IndiaToday\", \"India Today\", tweet)\n",
        "    tweet = re.sub(r\"HLPS\", \"helps\", tweet)\n",
        "    tweet = re.sub(r\"HOSTAGESTHROSW\", \"hostages throw\", tweet)\n",
        "    tweet = re.sub(r\"SNCTIONS\", \"sanctions\", tweet)\n",
        "    tweet = re.sub(r\"BidTime\", \"Bid Time\", tweet)\n",
        "    tweet = re.sub(r\"crunchysensible\", \"crunchy sensible\", tweet)\n",
        "    tweet = re.sub(r\"RandomActsOfRomance\", \"Random acts of romance\", tweet)\n",
        "    tweet = re.sub(r\"MomentsAtHill\", \"Moments at hill\", tweet)\n",
        "    tweet = re.sub(r\"eatshit\", \"eat shit\", tweet)\n",
        "    tweet = re.sub(r\"liveleakfun\", \"live leak fun\", tweet)\n",
        "    tweet = re.sub(r\"SahelNews\", \"Sahel News\", tweet)\n",
        "    tweet = re.sub(r\"abc7newsbayarea\", \"ABC 7 News Bay Area\", tweet)\n",
        "    tweet = re.sub(r\"facilitiesmanagement\", \"facilities management\", tweet)\n",
        "    tweet = re.sub(r\"facilitydude\", \"facility dude\", tweet)\n",
        "    tweet = re.sub(r\"CampLogistics\", \"Camp logistics\", tweet)\n",
        "    tweet = re.sub(r\"alaskapublic\", \"Alaska public\", tweet)\n",
        "    tweet = re.sub(r\"MarketResearch\", \"Market Research\", tweet)\n",
        "    tweet = re.sub(r\"AccuracyEsports\", \"Accuracy Esports\", tweet)\n",
        "    tweet = re.sub(r\"TheBodyShopAust\", \"The Body Shop Australia\", tweet)\n",
        "    tweet = re.sub(r\"yychail\", \"Calgary hail\", tweet)\n",
        "    tweet = re.sub(r\"yyctraffic\", \"Calgary traffic\", tweet)\n",
        "    tweet = re.sub(r\"eliotschool\", \"eliot school\", tweet)\n",
        "    tweet = re.sub(r\"TheBrokenCity\", \"The Broken City\", tweet)\n",
        "    tweet = re.sub(r\"OldsFireDept\", \"Olds Fire Department\", tweet)\n",
        "    tweet = re.sub(r\"RiverComplex\", \"River Complex\", tweet)\n",
        "    tweet = re.sub(r\"fieldworksmells\", \"field work smells\", tweet)\n",
        "    tweet = re.sub(r\"IranElection\", \"Iran Election\", tweet)\n",
        "    tweet = re.sub(r\"glowng\", \"glowing\", tweet)\n",
        "    tweet = re.sub(r\"kindlng\", \"kindling\", tweet)\n",
        "    tweet = re.sub(r\"riggd\", \"rigged\", tweet)\n",
        "    tweet = re.sub(r\"slownewsday\", \"slow news day\", tweet)\n",
        "    tweet = re.sub(r\"MyanmarFlood\", \"Myanmar Flood\", tweet)\n",
        "    tweet = re.sub(r\"abc7chicago\", \"ABC 7 Chicago\", tweet)\n",
        "    tweet = re.sub(r\"copolitics\", \"Colorado Politics\", tweet)\n",
        "    tweet = re.sub(r\"AdilGhumro\", \"Adil Ghumro\", tweet)\n",
        "    tweet = re.sub(r\"netbots\", \"net bots\", tweet)\n",
        "    tweet = re.sub(r\"byebyeroad\", \"bye bye road\", tweet)\n",
        "    tweet = re.sub(r\"massiveflooding\", \"massive flooding\", tweet)\n",
        "    tweet = re.sub(r\"EndofUS\", \"End of United States\", tweet)\n",
        "    tweet = re.sub(r\"35PM\", \"35 PM\", tweet)\n",
        "    tweet = re.sub(r\"greektheatrela\", \"Greek Theatre Los Angeles\", tweet)\n",
        "    tweet = re.sub(r\"76mins\", \"76 minutes\", tweet)\n",
        "    tweet = re.sub(r\"publicsafetyfirst\", \"public safety first\", tweet)\n",
        "    tweet = re.sub(r\"livesmatter\", \"lives matter\", tweet)\n",
        "    tweet = re.sub(r\"myhometown\", \"my hometown\", tweet)\n",
        "    tweet = re.sub(r\"tankerfire\", \"tanker fire\", tweet)\n",
        "    tweet = re.sub(r\"MEMORIALDAY\", \"memorial day\", tweet)\n",
        "    tweet = re.sub(r\"MEMORIAL_DAY\", \"memorial day\", tweet)\n",
        "    tweet = re.sub(r\"instaxbooty\", \"instagram booty\", tweet)\n",
        "    tweet = re.sub(r\"Jerusalem_Post\", \"Jerusalem Post\", tweet)\n",
        "    tweet = re.sub(r\"WayneRooney_INA\", \"Wayne Rooney\", tweet)\n",
        "    tweet = re.sub(r\"VirtualReality\", \"Virtual Reality\", tweet)\n",
        "    tweet = re.sub(r\"OculusRift\", \"Oculus Rift\", tweet)\n",
        "    tweet = re.sub(r\"OwenJones84\", \"Owen Jones\", tweet)\n",
        "    tweet = re.sub(r\"jeremycorbyn\", \"Jeremy Corbyn\", tweet)\n",
        "    tweet = re.sub(r\"paulrogers002\", \"Paul Rogers\", tweet)\n",
        "    tweet = re.sub(r\"mortalkombatx\", \"Mortal Kombat X\", tweet)\n",
        "    tweet = re.sub(r\"mortalkombat\", \"Mortal Kombat\", tweet)\n",
        "    tweet = re.sub(r\"FilipeCoelho92\", \"Filipe Coelho\", tweet)\n",
        "    tweet = re.sub(r\"OnlyQuakeNews\", \"Only Quake News\", tweet)\n",
        "    tweet = re.sub(r\"kostumes\", \"costumes\", tweet)\n",
        "    tweet = re.sub(r\"YEEESSSS\", \"yes\", tweet)\n",
        "    tweet = re.sub(r\"ToshikazuKatayama\", \"Toshikazu Katayama\", tweet)\n",
        "    tweet = re.sub(r\"IntlDevelopment\", \"Intl Development\", tweet)\n",
        "    tweet = re.sub(r\"ExtremeWeather\", \"Extreme Weather\", tweet)\n",
        "    tweet = re.sub(r\"WereNotGruberVoters\", \"We are not gruber voters\", tweet)\n",
        "    tweet = re.sub(r\"NewsThousands\", \"News Thousands\", tweet)\n",
        "    tweet = re.sub(r\"EdmundAdamus\", \"Edmund Adamus\", tweet)\n",
        "    tweet = re.sub(r\"EyewitnessWV\", \"Eye witness WV\", tweet)\n",
        "    tweet = re.sub(r\"PhiladelphiaMuseu\", \"Philadelphia Museum\", tweet)\n",
        "    tweet = re.sub(r\"DublinComicCon\", \"Dublin Comic Con\", tweet)\n",
        "    tweet = re.sub(r\"NicholasBrendon\", \"Nicholas Brendon\", tweet)\n",
        "    tweet = re.sub(r\"Alltheway80s\", \"All the way 80s\", tweet)\n",
        "    tweet = re.sub(r\"FromTheField\", \"From the field\", tweet)\n",
        "    tweet = re.sub(r\"NorthIowa\", \"North Iowa\", tweet)\n",
        "    tweet = re.sub(r\"WillowFire\", \"Willow Fire\", tweet)\n",
        "    tweet = re.sub(r\"MadRiverComplex\", \"Mad River Complex\", tweet)\n",
        "    tweet = re.sub(r\"feelingmanly\", \"feeling manly\", tweet)\n",
        "    tweet = re.sub(r\"stillnotoverit\", \"still not over it\", tweet)\n",
        "    tweet = re.sub(r\"FortitudeValley\", \"Fortitude Valley\", tweet)\n",
        "    tweet = re.sub(r\"CoastpowerlineTramTr\", \"Coast powerline\", tweet)\n",
        "    tweet = re.sub(r\"ServicesGold\", \"Services Gold\", tweet)\n",
        "    tweet = re.sub(r\"NewsbrokenEmergency\", \"News broken emergency\", tweet)\n",
        "    tweet = re.sub(r\"Evaucation\", \"evacuation\", tweet)\n",
        "    tweet = re.sub(r\"leaveevacuateexitbe\", \"leave evacuate exit be\", tweet)\n",
        "    tweet = re.sub(r\"P_EOPLE\", \"PEOPLE\", tweet)\n",
        "    tweet = re.sub(r\"Tubestrike\", \"tube strike\", tweet)\n",
        "    tweet = re.sub(r\"CLASS_SICK\", \"CLASS SICK\", tweet)\n",
        "    tweet = re.sub(r\"localplumber\", \"local plumber\", tweet)\n",
        "    tweet = re.sub(r\"awesomejobsiri\", \"awesome job siri\", tweet)\n",
        "    tweet = re.sub(r\"PayForItHow\", \"Pay for it how\", tweet)\n",
        "    tweet = re.sub(r\"ThisIsAfrica\", \"This is Africa\", tweet)\n",
        "    tweet = re.sub(r\"crimeairnetwork\", \"crime air network\", tweet)\n",
        "    tweet = re.sub(r\"KimAcheson\", \"Kim Acheson\", tweet)\n",
        "    tweet = re.sub(r\"cityofcalgary\", \"City of Calgary\", tweet)\n",
        "    tweet = re.sub(r\"prosyndicate\", \"pro syndicate\", tweet)\n",
        "    tweet = re.sub(r\"660NEWS\", \"660 NEWS\", tweet)\n",
        "    tweet = re.sub(r\"BusInsMagazine\", \"Business Insurance Magazine\", tweet)\n",
        "    tweet = re.sub(r\"wfocus\", \"focus\", tweet)\n",
        "    tweet = re.sub(r\"ShastaDam\", \"Shasta Dam\", tweet)\n",
        "    tweet = re.sub(r\"go2MarkFranco\", \"Mark Franco\", tweet)\n",
        "    tweet = re.sub(r\"StephGHinojosa\", \"Steph Hinojosa\", tweet)\n",
        "    tweet = re.sub(r\"Nashgrier\", \"Nash Grier\", tweet)\n",
        "    tweet = re.sub(r\"NashNewVideo\", \"Nash new video\", tweet)\n",
        "    tweet = re.sub(r\"IWouldntGetElectedBecause\", \"I would not get elected because\", tweet)\n",
        "    tweet = re.sub(r\"SHGames\", \"Sledgehammer Games\", tweet)\n",
        "    tweet = re.sub(r\"bedhair\", \"bed hair\", tweet)\n",
        "    tweet = re.sub(r\"JoelHeyman\", \"Joel Heyman\", tweet)\n",
        "    tweet = re.sub(r\"viaYouTube\", \"via YouTube\", tweet)\n",
        "           \n",
        "    # Urls\n",
        "    tweet = re.sub(r\"https?:\\/\\/t.co\\/[A-Za-z0-9]+\", \"\", tweet)\n",
        "        \n",
        "    # Words with punctuations and special characters\n",
        "    punctuations = '@#!?+&*[]-%.:/();$=><|{}^' + \"'`\"\n",
        "    for p in punctuations:\n",
        "        tweet = tweet.replace(p, f' {p} ')\n",
        "        \n",
        "    # ... and ..\n",
        "    tweet = tweet.replace('...', ' ... ')\n",
        "    if '...' not in tweet:\n",
        "        tweet = tweet.replace('..', ' ... ')      \n",
        "        \n",
        "    # Acronyms\n",
        "    tweet = re.sub(r\"MH370\", \"Malaysia Airlines Flight 370\", tweet)\n",
        "    tweet = re.sub(r\"mÌ¼sica\", \"music\", tweet)\n",
        "    tweet = re.sub(r\"okwx\", \"Oklahoma City Weather\", tweet)\n",
        "    tweet = re.sub(r\"arwx\", \"Arkansas Weather\", tweet)    \n",
        "    tweet = re.sub(r\"gawx\", \"Georgia Weather\", tweet)  \n",
        "    tweet = re.sub(r\"scwx\", \"South Carolina Weather\", tweet)  \n",
        "    tweet = re.sub(r\"cawx\", \"California Weather\", tweet)\n",
        "    tweet = re.sub(r\"tnwx\", \"Tennessee Weather\", tweet)\n",
        "    tweet = re.sub(r\"azwx\", \"Arizona Weather\", tweet)  \n",
        "    tweet = re.sub(r\"alwx\", \"Alabama Weather\", tweet)\n",
        "    tweet = re.sub(r\"wordpressdotcom\", \"wordpress\", tweet)    \n",
        "    tweet = re.sub(r\"usNWSgov\", \"United States National Weather Service\", tweet)\n",
        "    tweet = re.sub(r\"Suruc\", \"Sanliurfa\", tweet)   \n",
        "    \n",
        "    # Grouping same words without embeddings\n",
        "    tweet = re.sub(r\"Bestnaijamade\", \"bestnaijamade\", tweet)\n",
        "    tweet = re.sub(r\"SOUDELOR\", \"Soudelor\", tweet)\n",
        "    \n",
        "    return tweet\n",
        "\n",
        "data['text_cleaned'] = data['text'].apply(clean)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7201877e-e2a0-480b-b0ef-af09603e510b",
      "metadata": {
        "id": "7201877e-e2a0-480b-b0ef-af09603e510b"
      },
      "outputs": [],
      "source": [
        "data.to_csv(\"data/data-w-cleaned-text.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = pd.read_csv(\"data/data-w-cleaned-text.csv\")\n",
        "print(data.shape)\n",
        "data.sample(3)"
      ],
      "metadata": {
        "id": "KcFnPGDHuL3H",
        "outputId": "f9cd8e61-9097-4699-cdad-2cd945887baf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        }
      },
      "id": "KcFnPGDHuL3H",
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(10876, 7)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        id      keyword      location  \\\n",
              "2498  3588     desolate           NaN   \n",
              "211    298  annihilated  New York, NY   \n",
              "2730  3922   devastated   Bournemouth   \n",
              "\n",
              "                                                   text  target   Dataset  \\\n",
              "2498  Psalms 34:22 The Lord redeemeth the soul of hi...     0.0  Training   \n",
              "211         Uribe just annihilated that baseball. #Mets     0.0  Training   \n",
              "2730  DEVASTATED ISNT THE WORD ROSS OUT OF ALL PEOPL...     0.0  Training   \n",
              "\n",
              "                                           text_cleaned  \n",
              "2498  Psalms 34 : 22 The Lord redeemeth the soul of ...  \n",
              "211     Uribe just annihilated that baseball .   # Mets  \n",
              "2730  DEVASTATED ISNT THE WORD ROSS OUT OF ALL PEOPL...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-9d9d9ba7-35d6-4dc9-9c8a-429da8a9d74d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>keyword</th>\n",
              "      <th>location</th>\n",
              "      <th>text</th>\n",
              "      <th>target</th>\n",
              "      <th>Dataset</th>\n",
              "      <th>text_cleaned</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2498</th>\n",
              "      <td>3588</td>\n",
              "      <td>desolate</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Psalms 34:22 The Lord redeemeth the soul of hi...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Training</td>\n",
              "      <td>Psalms 34 : 22 The Lord redeemeth the soul of ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>298</td>\n",
              "      <td>annihilated</td>\n",
              "      <td>New York, NY</td>\n",
              "      <td>Uribe just annihilated that baseball. #Mets</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Training</td>\n",
              "      <td>Uribe just annihilated that baseball .   # Mets</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2730</th>\n",
              "      <td>3922</td>\n",
              "      <td>devastated</td>\n",
              "      <td>Bournemouth</td>\n",
              "      <td>DEVASTATED ISNT THE WORD ROSS OUT OF ALL PEOPL...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>Training</td>\n",
              "      <td>DEVASTATED ISNT THE WORD ROSS OUT OF ALL PEOPL...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9d9d9ba7-35d6-4dc9-9c8a-429da8a9d74d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-9d9d9ba7-35d6-4dc9-9c8a-429da8a9d74d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-9d9d9ba7-35d6-4dc9-9c8a-429da8a9d74d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "fedf0557-e8c4-4eb2-99f9-07aa564b0622",
      "metadata": {
        "id": "fedf0557-e8c4-4eb2-99f9-07aa564b0622"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "6d2c5c1d-7ed4-4923-a118-d1cfe9c0ff2f",
      "metadata": {
        "id": "6d2c5c1d-7ed4-4923-a118-d1cfe9c0ff2f",
        "outputId": "81855a11-b4e2-480d-a6e3-75347f3d041b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6090,), (1523,), (3263,), (6090,), (1523,))"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "X_tmp, y_tmp = data.loc[ data.Dataset=='Training', 'text' ], data.loc[ data.Dataset=='Training', 'target' ]\n",
        "X_train, X_val, y_train, y_val = train_test_split(X_tmp, y_tmp, stratify=y_tmp, test_size=0.2, random_state=42)\n",
        "X_test = data.loc[ data.Dataset=='Testing', 'text' ]\n",
        "\n",
        "X_train.shape, X_val.shape, X_test.shape, y_train.shape, y_val.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c1f55984-7875-4ed0-9f4d-d61cd35e767c",
      "metadata": {
        "id": "c1f55984-7875-4ed0-9f4d-d61cd35e767c"
      },
      "source": [
        "# Model v1"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-text "
      ],
      "metadata": {
        "id": "TfHYh0I8vH0M",
        "outputId": "05bdab7a-cd79-4914-a912-c9522043f163",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "id": "TfHYh0I8vH0M",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m82.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow<2.12,>=2.11.0\n",
            "  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow-text) (0.12.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.6.3)\n",
            "Collecting keras<2.12,>=2.11.0\n",
            "  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (0.29.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.3.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.51.1)\n",
            "Collecting tensorflow-estimator<2.12,>=2.11.0\n",
            "  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m47.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (21.3)\n",
            "Requirement already satisfied: protobuf<3.20,>=3.9.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (3.19.6)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (2.1.1)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (57.4.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.14.1)\n",
            "Collecting flatbuffers>=2.0\n",
            "  Downloading flatbuffers-23.1.4-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (0.4.0)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (1.21.6)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (0.2.0)\n",
            "Collecting tensorboard<2.12,>=2.11\n",
            "  Downloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (14.0.6)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.8/dist-packages (from tensorflow<2.12,>=2.11.0->tensorflow-text) (4.4.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.38.4)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.6.1)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (1.8.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.4.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2.25.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2.15.0)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.4.6)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.0.9)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (5.2.0)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.2.8)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (5.2.0)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (1.24.3)\n",
            "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (4.0.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2022.12.7)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (2.10)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.11.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (0.4.8)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow<2.12,>=2.11.0->tensorflow-text) (3.2.2)\n",
            "Installing collected packages: flatbuffers, tensorflow-estimator, keras, tensorboard, tensorflow, tensorflow-text\n",
            "  Attempting uninstall: flatbuffers\n",
            "    Found existing installation: flatbuffers 1.12\n",
            "    Uninstalling flatbuffers-1.12:\n",
            "      Successfully uninstalled flatbuffers-1.12\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.9.0\n",
            "    Uninstalling tensorflow-estimator-2.9.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.9.0\n",
            "  Attempting uninstall: keras\n",
            "    Found existing installation: keras 2.9.0\n",
            "    Uninstalling keras-2.9.0:\n",
            "      Successfully uninstalled keras-2.9.0\n",
            "  Attempting uninstall: tensorboard\n",
            "    Found existing installation: tensorboard 2.9.1\n",
            "    Uninstalling tensorboard-2.9.1:\n",
            "      Successfully uninstalled tensorboard-2.9.1\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.9.2\n",
            "    Uninstalling tensorflow-2.9.2:\n",
            "      Successfully uninstalled tensorflow-2.9.2\n",
            "Successfully installed flatbuffers-23.1.4 keras-2.11.0 tensorboard-2.11.0 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-text-2.11.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "flatbuffers",
                  "keras",
                  "tensorboard",
                  "tensorflow",
                  "tensorflow_estimator"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "2efec45c-ccd6-41b0-a50d-c201939c0e91",
      "metadata": {
        "id": "2efec45c-ccd6-41b0-a50d-c201939c0e91"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Input, Dense, Dropout, Lambda\n",
        "from tensorflow.keras.callbacks import EarlyStopping"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9b458ce7-c8d5-48fe-bc22-57812d37124f",
      "metadata": {
        "id": "9b458ce7-c8d5-48fe-bc22-57812d37124f"
      },
      "source": [
        "## Building model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "8666f8d9-0d9e-4c5b-be80-4be5fdb5d985",
      "metadata": {
        "id": "8666f8d9-0d9e-4c5b-be80-4be5fdb5d985",
        "outputId": "6cc42dac-9a1e-4521-c4b0-cc74a30cbf97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " keras_layer_4 (KerasLayer)     {'input_mask': (Non  0           ['input_3[0][0]']                \n",
            "                                e, 128),                                                          \n",
            "                                 'input_word_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128)}                                                      \n",
            "                                                                                                  \n",
            " keras_layer_5 (KerasLayer)     {'encoder_outputs':  109482241   ['keras_layer_4[0][0]',          \n",
            "                                 [(None, 128, 768),               'keras_layer_4[0][1]',          \n",
            "                                 (None, 128, 768),                'keras_layer_4[0][2]']          \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'default': (None,                                                \n",
            "                                768),                                                             \n",
            "                                 'pooled_output': (                                               \n",
            "                                None, 768),                                                       \n",
            "                                 'sequence_output':                                               \n",
            "                                 (None, 128, 768)}                                                \n",
            "                                                                                                  \n",
            " dense_4 (Dense)                (None, 512)          393728      ['keras_layer_5[0][13]']         \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 512)          0           ['dense_4[0][0]']                \n",
            "                                                                                                  \n",
            " dense_5 (Dense)                (None, 1)            513         ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,876,482\n",
            "Trainable params: 394,241\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "text_input = Input(shape=(), dtype=tf.string)\n",
        "preprocessed_text = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")(text_input)\n",
        "encoded_text = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\", trainable=False)(preprocessed_text)[\"pooled_output\"]\n",
        "\n",
        "output = Dense(512, activation='relu')(encoded_text)\n",
        "output = Dropout(0.3)(output)\n",
        "# output = Dense(1024, activation='relu')(output)\n",
        "# output = Dropout(0.3)(output)\n",
        "output = Dense(1, activation='sigmoid')(output)\n",
        "\n",
        "model = tf.keras.Model(inputs=[text_input], outputs=[output])\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "7f979d2c-f56d-42d9-82d7-230deaaad523",
      "metadata": {
        "id": "7f979d2c-f56d-42d9-82d7-230deaaad523"
      },
      "outputs": [],
      "source": [
        "import keras.backend as K\n",
        "\n",
        "\n",
        "def f1_score(y_true, y_pred):  # Taken from old keras source code\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    precision = true_positives / (predicted_positives + K.epsilon())\n",
        "    recall = true_positives / (possible_positives + K.epsilon())\n",
        "    f1_val = 2 * (precision*recall) / (precision+recall+K.epsilon())\n",
        "    return f1_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "8e96e178-ad2f-466a-94ef-da7f5a2d6268",
      "metadata": {
        "id": "8e96e178-ad2f-466a-94ef-da7f5a2d6268"
      },
      "outputs": [],
      "source": [
        "METRICS = [\n",
        "    'accuracy',\n",
        "    tf.keras.metrics.Precision(name='precision'),\n",
        "    tf.keras.metrics.Recall(name='recall'),\n",
        "    f1_score,\n",
        "]\n",
        "\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=METRICS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "0c8803d5-ff14-4261-b4f4-ba545aa3bbaf",
      "metadata": {
        "scrolled": true,
        "tags": [],
        "id": "0c8803d5-ff14-4261-b4f4-ba545aa3bbaf",
        "outputId": "2d00af3f-a013-4137-d154-4da1eb955bda",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n",
            "12/12 - 193s - loss: 1.1792 - accuracy: 0.5450 - precision: 0.4745 - recall: 0.5480 - f1_score: 0.3970 - val_loss: 0.6961 - val_accuracy: 0.5831 - val_precision: 0.6557 - val_recall: 0.0612 - val_f1_score: 0.1115 - 193s/epoch - 16s/step\n",
            "Epoch 2/100\n",
            "12/12 - 184s - loss: 0.7194 - accuracy: 0.6097 - precision: 0.5587 - recall: 0.4364 - f1_score: 0.4090 - val_loss: 0.6571 - val_accuracy: 0.6047 - val_precision: 0.7063 - val_recall: 0.1361 - val_f1_score: 0.2280 - 184s/epoch - 15s/step\n",
            "Epoch 3/100\n",
            "12/12 - 181s - loss: 0.6272 - accuracy: 0.6606 - precision: 0.6326 - recall: 0.5013 - f1_score: 0.5256 - val_loss: 0.6044 - val_accuracy: 0.6632 - val_precision: 0.7196 - val_recall: 0.3532 - val_f1_score: 0.4728 - 181s/epoch - 15s/step\n",
            "Epoch 4/100\n",
            "12/12 - 180s - loss: 0.6042 - accuracy: 0.6811 - precision: 0.6556 - recall: 0.5434 - f1_score: 0.5865 - val_loss: 0.5829 - val_accuracy: 0.7058 - val_precision: 0.7020 - val_recall: 0.5474 - val_f1_score: 0.6152 - 180s/epoch - 15s/step\n",
            "Epoch 5/100\n",
            "12/12 - 180s - loss: 0.5893 - accuracy: 0.6943 - precision: 0.6619 - recall: 0.5896 - f1_score: 0.6225 - val_loss: 0.5763 - val_accuracy: 0.7072 - val_precision: 0.6585 - val_recall: 0.6606 - val_f1_score: 0.6594 - 180s/epoch - 15s/step\n",
            "Epoch 6/100\n",
            "12/12 - 179s - loss: 0.5819 - accuracy: 0.7087 - precision: 0.6724 - recall: 0.6282 - f1_score: 0.6454 - val_loss: 0.5678 - val_accuracy: 0.7163 - val_precision: 0.7048 - val_recall: 0.5841 - val_f1_score: 0.6387 - 179s/epoch - 15s/step\n",
            "Epoch 7/100\n",
            "12/12 - 178s - loss: 0.5764 - accuracy: 0.7123 - precision: 0.6916 - recall: 0.5965 - f1_score: 0.6362 - val_loss: 0.5610 - val_accuracy: 0.7209 - val_precision: 0.7078 - val_recall: 0.5963 - val_f1_score: 0.6469 - 178s/epoch - 15s/step\n",
            "Epoch 8/100\n",
            "12/12 - 179s - loss: 0.5688 - accuracy: 0.7202 - precision: 0.6942 - recall: 0.6236 - f1_score: 0.6567 - val_loss: 0.5557 - val_accuracy: 0.7229 - val_precision: 0.6818 - val_recall: 0.6651 - val_f1_score: 0.6731 - 179s/epoch - 15s/step\n",
            "Epoch 9/100\n",
            "12/12 - 173s - loss: 0.5597 - accuracy: 0.7268 - precision: 0.6990 - recall: 0.6397 - f1_score: 0.6673 - val_loss: 0.5522 - val_accuracy: 0.7216 - val_precision: 0.6716 - val_recall: 0.6881 - val_f1_score: 0.6793 - 173s/epoch - 14s/step\n",
            "Epoch 10/100\n",
            "12/12 - 181s - loss: 0.5530 - accuracy: 0.7366 - precision: 0.7149 - recall: 0.6439 - f1_score: 0.6773 - val_loss: 0.5424 - val_accuracy: 0.7321 - val_precision: 0.7228 - val_recall: 0.6101 - val_f1_score: 0.6611 - 181s/epoch - 15s/step\n",
            "Epoch 11/100\n",
            "12/12 - 179s - loss: 0.5502 - accuracy: 0.7376 - precision: 0.7151 - recall: 0.6473 - f1_score: 0.6796 - val_loss: 0.5415 - val_accuracy: 0.7406 - val_precision: 0.7726 - val_recall: 0.5612 - val_f1_score: 0.6496 - 179s/epoch - 15s/step\n",
            "Epoch 12/100\n",
            "12/12 - 178s - loss: 0.5484 - accuracy: 0.7314 - precision: 0.7081 - recall: 0.6378 - f1_score: 0.6691 - val_loss: 0.5323 - val_accuracy: 0.7387 - val_precision: 0.7140 - val_recall: 0.6529 - val_f1_score: 0.6818 - 178s/epoch - 15s/step\n",
            "Epoch 13/100\n",
            "12/12 - 177s - loss: 0.5404 - accuracy: 0.7437 - precision: 0.7284 - recall: 0.6435 - f1_score: 0.6825 - val_loss: 0.5273 - val_accuracy: 0.7479 - val_precision: 0.7586 - val_recall: 0.6055 - val_f1_score: 0.6731 - 177s/epoch - 15s/step\n",
            "Epoch 14/100\n",
            "12/12 - 179s - loss: 0.5357 - accuracy: 0.7511 - precision: 0.7360 - recall: 0.6561 - f1_score: 0.6923 - val_loss: 0.5214 - val_accuracy: 0.7479 - val_precision: 0.7586 - val_recall: 0.6055 - val_f1_score: 0.6732 - 179s/epoch - 15s/step\n",
            "Epoch 15/100\n",
            "12/12 - 171s - loss: 0.5288 - accuracy: 0.7529 - precision: 0.7471 - recall: 0.6423 - f1_score: 0.6906 - val_loss: 0.5186 - val_accuracy: 0.7584 - val_precision: 0.7277 - val_recall: 0.6988 - val_f1_score: 0.7124 - 171s/epoch - 14s/step\n",
            "Epoch 16/100\n",
            "12/12 - 177s - loss: 0.5297 - accuracy: 0.7453 - precision: 0.7257 - recall: 0.6549 - f1_score: 0.6865 - val_loss: 0.5248 - val_accuracy: 0.7472 - val_precision: 0.6876 - val_recall: 0.7538 - val_f1_score: 0.7186 - 177s/epoch - 15s/step\n",
            "Epoch 17/100\n",
            "12/12 - 182s - loss: 0.5339 - accuracy: 0.7438 - precision: 0.7354 - recall: 0.6309 - f1_score: 0.6742 - val_loss: 0.5333 - val_accuracy: 0.7321 - val_precision: 0.6577 - val_recall: 0.7844 - val_f1_score: 0.7151 - 182s/epoch - 15s/step\n",
            "Epoch 18/100\n",
            "12/12 - 182s - loss: 0.5320 - accuracy: 0.7396 - precision: 0.7242 - recall: 0.6362 - f1_score: 0.6712 - val_loss: 0.5078 - val_accuracy: 0.7590 - val_precision: 0.7364 - val_recall: 0.6835 - val_f1_score: 0.7085 - 182s/epoch - 15s/step\n",
            "Epoch 19/100\n",
            "12/12 - 177s - loss: 0.5197 - accuracy: 0.7571 - precision: 0.7399 - recall: 0.6706 - f1_score: 0.7012 - val_loss: 0.5045 - val_accuracy: 0.7617 - val_precision: 0.7975 - val_recall: 0.5963 - val_f1_score: 0.6819 - 177s/epoch - 15s/step\n",
            "Epoch 20/100\n",
            "12/12 - 179s - loss: 0.5123 - accuracy: 0.7631 - precision: 0.7500 - recall: 0.6729 - f1_score: 0.7086 - val_loss: 0.5000 - val_accuracy: 0.7610 - val_precision: 0.7767 - val_recall: 0.6223 - val_f1_score: 0.6908 - 179s/epoch - 15s/step\n",
            "Epoch 21/100\n",
            "12/12 - 179s - loss: 0.5056 - accuracy: 0.7657 - precision: 0.7558 - recall: 0.6718 - f1_score: 0.7086 - val_loss: 0.5183 - val_accuracy: 0.7571 - val_precision: 0.8604 - val_recall: 0.5183 - val_f1_score: 0.6463 - 179s/epoch - 15s/step\n",
            "Epoch 22/100\n",
            "12/12 - 179s - loss: 0.5105 - accuracy: 0.7614 - precision: 0.7553 - recall: 0.6580 - f1_score: 0.7003 - val_loss: 0.4972 - val_accuracy: 0.7695 - val_precision: 0.8217 - val_recall: 0.5917 - val_f1_score: 0.6871 - 179s/epoch - 15s/step\n",
            "Epoch 23/100\n",
            "12/12 - 177s - loss: 0.5042 - accuracy: 0.7645 - precision: 0.7540 - recall: 0.6710 - f1_score: 0.7083 - val_loss: 0.4938 - val_accuracy: 0.7656 - val_precision: 0.8037 - val_recall: 0.6009 - val_f1_score: 0.6872 - 177s/epoch - 15s/step\n",
            "Epoch 24/100\n",
            "12/12 - 170s - loss: 0.5035 - accuracy: 0.7667 - precision: 0.7609 - recall: 0.6664 - f1_score: 0.7094 - val_loss: 0.4948 - val_accuracy: 0.7676 - val_precision: 0.8319 - val_recall: 0.5749 - val_f1_score: 0.6792 - 170s/epoch - 14s/step\n",
            "Epoch 25/100\n",
            "12/12 - 177s - loss: 0.5111 - accuracy: 0.7604 - precision: 0.7539 - recall: 0.6569 - f1_score: 0.6968 - val_loss: 0.4856 - val_accuracy: 0.7715 - val_precision: 0.7865 - val_recall: 0.6422 - val_f1_score: 0.7065 - 177s/epoch - 15s/step\n",
            "Epoch 26/100\n",
            "12/12 - 180s - loss: 0.4962 - accuracy: 0.7729 - precision: 0.7599 - recall: 0.6893 - f1_score: 0.7221 - val_loss: 0.4833 - val_accuracy: 0.7735 - val_precision: 0.7910 - val_recall: 0.6422 - val_f1_score: 0.7081 - 180s/epoch - 15s/step\n",
            "Epoch 27/100\n",
            "12/12 - 178s - loss: 0.4929 - accuracy: 0.7714 - precision: 0.7676 - recall: 0.6714 - f1_score: 0.7144 - val_loss: 0.4798 - val_accuracy: 0.7800 - val_precision: 0.8121 - val_recall: 0.6346 - val_f1_score: 0.7117 - 178s/epoch - 15s/step\n",
            "Epoch 28/100\n",
            "12/12 - 171s - loss: 0.4887 - accuracy: 0.7757 - precision: 0.7718 - recall: 0.6786 - f1_score: 0.7219 - val_loss: 0.4823 - val_accuracy: 0.7761 - val_precision: 0.7346 - val_recall: 0.7492 - val_f1_score: 0.7412 - 171s/epoch - 14s/step\n",
            "Epoch 29/100\n",
            "12/12 - 176s - loss: 0.4872 - accuracy: 0.7768 - precision: 0.7668 - recall: 0.6909 - f1_score: 0.7255 - val_loss: 0.4748 - val_accuracy: 0.7820 - val_precision: 0.7927 - val_recall: 0.6667 - val_f1_score: 0.7233 - 176s/epoch - 15s/step\n",
            "Epoch 30/100\n",
            "12/12 - 177s - loss: 0.4860 - accuracy: 0.7752 - precision: 0.7699 - recall: 0.6802 - f1_score: 0.7207 - val_loss: 0.4732 - val_accuracy: 0.7807 - val_precision: 0.7606 - val_recall: 0.7141 - val_f1_score: 0.7361 - 177s/epoch - 15s/step\n",
            "Epoch 31/100\n",
            "12/12 - 177s - loss: 0.4817 - accuracy: 0.7805 - precision: 0.7744 - recall: 0.6901 - f1_score: 0.7286 - val_loss: 0.4793 - val_accuracy: 0.7774 - val_precision: 0.8373 - val_recall: 0.5979 - val_f1_score: 0.6967 - 177s/epoch - 15s/step\n",
            "Epoch 32/100\n",
            "12/12 - 177s - loss: 0.4934 - accuracy: 0.7708 - precision: 0.7710 - recall: 0.6637 - f1_score: 0.7095 - val_loss: 0.4718 - val_accuracy: 0.7873 - val_precision: 0.7670 - val_recall: 0.7248 - val_f1_score: 0.7448 - 177s/epoch - 15s/step\n",
            "Epoch 33/100\n",
            "12/12 - 182s - loss: 0.4894 - accuracy: 0.7731 - precision: 0.7615 - recall: 0.6870 - f1_score: 0.7189 - val_loss: 0.4865 - val_accuracy: 0.7741 - val_precision: 0.7147 - val_recall: 0.7890 - val_f1_score: 0.7496 - 182s/epoch - 15s/step\n",
            "Epoch 34/100\n",
            "12/12 - 182s - loss: 0.4794 - accuracy: 0.7842 - precision: 0.7771 - recall: 0.6981 - f1_score: 0.7351 - val_loss: 0.4744 - val_accuracy: 0.7794 - val_precision: 0.7345 - val_recall: 0.7615 - val_f1_score: 0.7475 - 182s/epoch - 15s/step\n",
            "Epoch 35/100\n",
            "12/12 - 183s - loss: 0.4770 - accuracy: 0.7780 - precision: 0.7709 - recall: 0.6878 - f1_score: 0.7265 - val_loss: 0.4648 - val_accuracy: 0.7991 - val_precision: 0.7959 - val_recall: 0.7156 - val_f1_score: 0.7531 - 183s/epoch - 15s/step\n",
            "Epoch 36/100\n",
            "12/12 - 184s - loss: 0.4764 - accuracy: 0.7837 - precision: 0.7829 - recall: 0.6874 - f1_score: 0.7310 - val_loss: 0.4680 - val_accuracy: 0.7846 - val_precision: 0.7485 - val_recall: 0.7508 - val_f1_score: 0.7493 - 184s/epoch - 15s/step\n",
            "Epoch 37/100\n",
            "12/12 - 183s - loss: 0.4771 - accuracy: 0.7805 - precision: 0.7800 - recall: 0.6813 - f1_score: 0.7252 - val_loss: 0.4788 - val_accuracy: 0.7859 - val_precision: 0.7310 - val_recall: 0.7936 - val_f1_score: 0.7607 - 183s/epoch - 15s/step\n",
            "Epoch 38/100\n",
            "12/12 - 182s - loss: 0.4772 - accuracy: 0.7788 - precision: 0.7721 - recall: 0.6886 - f1_score: 0.7271 - val_loss: 0.4693 - val_accuracy: 0.7879 - val_precision: 0.7481 - val_recall: 0.7630 - val_f1_score: 0.7550 - 182s/epoch - 15s/step\n",
            "Epoch 39/100\n",
            "12/12 - 175s - loss: 0.4742 - accuracy: 0.7828 - precision: 0.7674 - recall: 0.7096 - f1_score: 0.7371 - val_loss: 0.4947 - val_accuracy: 0.7663 - val_precision: 0.8782 - val_recall: 0.5291 - val_f1_score: 0.6596 - 175s/epoch - 15s/step\n",
            "Epoch 40/100\n",
            "12/12 - 182s - loss: 0.4702 - accuracy: 0.7836 - precision: 0.7855 - recall: 0.6828 - f1_score: 0.7272 - val_loss: 0.4594 - val_accuracy: 0.7984 - val_precision: 0.7966 - val_recall: 0.7125 - val_f1_score: 0.7516 - 182s/epoch - 15s/step\n",
            "Epoch 41/100\n",
            "12/12 - 177s - loss: 0.4668 - accuracy: 0.7882 - precision: 0.7827 - recall: 0.7019 - f1_score: 0.7392 - val_loss: 0.4597 - val_accuracy: 0.7984 - val_precision: 0.8017 - val_recall: 0.7049 - val_f1_score: 0.7497 - 177s/epoch - 15s/step\n",
            "Epoch 42/100\n",
            "12/12 - 183s - loss: 0.4724 - accuracy: 0.7865 - precision: 0.7864 - recall: 0.6909 - f1_score: 0.7315 - val_loss: 0.4575 - val_accuracy: 0.7958 - val_precision: 0.7798 - val_recall: 0.7309 - val_f1_score: 0.7540 - 183s/epoch - 15s/step\n",
            "Epoch 43/100\n",
            "12/12 - 181s - loss: 0.4654 - accuracy: 0.7913 - precision: 0.7854 - recall: 0.7077 - f1_score: 0.7433 - val_loss: 0.4561 - val_accuracy: 0.8024 - val_precision: 0.8048 - val_recall: 0.7125 - val_f1_score: 0.7552 - 181s/epoch - 15s/step\n",
            "Epoch 44/100\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-5c16efb7b388>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit(X_train, y_train,\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m           \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mEarlyStopping\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatience\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrestore_best_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1648\u001b[0m                         ):\n\u001b[1;32m   1649\u001b[0m                             \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1650\u001b[0;31m                             \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1651\u001b[0m                             \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1652\u001b[0m                                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    878\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 880\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    881\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    882\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    910\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_no_variable_creation_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_variable_creation_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/tracing_compiler.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m       (concrete_function,\n\u001b[1;32m    133\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m--> 134\u001b[0;31m     return concrete_function._call_flat(\n\u001b[0m\u001b[1;32m    135\u001b[0m         filtered_flat_args, captured_inputs=concrete_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m    136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1743\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1745\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1746\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/polymorphic_function/monomorphic_function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    376\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 378\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    379\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    380\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     53\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     54\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "model.fit(X_train, y_train,\n",
        "          batch_size=512,\n",
        "          epochs=100,\n",
        "          validation_data=(X_val, y_val),\n",
        "          callbacks=[EarlyStopping(patience=10, restore_best_weights=True)],\n",
        "          verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "78dd264e-4220-4072-9eb2-5eeed5d74baa",
      "metadata": {
        "id": "78dd264e-4220-4072-9eb2-5eeed5d74baa"
      },
      "outputs": [],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8c421076-238f-411d-9a3a-d747a4e56352",
      "metadata": {
        "id": "8c421076-238f-411d-9a3a-d747a4e56352"
      },
      "outputs": [],
      "source": [
        "solution = pd.Series(y_pred.reshape(1,-1)[0]).apply(lambda prob : 1 if prob>=0.5 else 0)\n",
        "solution.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d02824eb-e465-41e4-96bc-949cb5bc4b76",
      "metadata": {
        "id": "d02824eb-e465-41e4-96bc-949cb5bc4b76"
      },
      "outputs": [],
      "source": [
        "solution = solution.to_frame().rename(columns={0:'target'})\n",
        "solution['id'] = test_data.id\n",
        "solution = solution[['id', 'target']]\n",
        "solution.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d5cad6b6-281e-4f12-abcc-5ca5049f7cd2",
      "metadata": {
        "id": "d5cad6b6-281e-4f12-abcc-5ca5049f7cd2"
      },
      "outputs": [],
      "source": [
        "solution.to_csv(\"data/solutions/deep_model_submission.csv\", index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "26d7c682-c19a-4f90-8674-a58f44663e91",
      "metadata": {
        "id": "26d7c682-c19a-4f90-8674-a58f44663e91"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.15"
    },
    "colab": {
      "provenance": []
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}